{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the final model\n",
    "Once we have obtained the continuous quality metric for join detection, we will use it to generate a predictive model that can efficiently, and in a very lightweight fashion, detect similarities between columns of a data lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwFeRi_OjHzB",
    "outputId": "4bfea26a-41e2-41a1-833e-7314cb8bb917"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'C:/Projects/freyja/data/'\n",
    "models_path = 'C:/Projects/freyja_plus_more/models_prenormalized_base'\n",
    "distances = pd.read_csv(f'C:/Projects/freyja_plus_more/distances/distances_model_prenormalized_base.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-svj3C4JrAFi"
   },
   "source": [
    "# Preparing the data\n",
    "\n",
    "We will:\n",
    "- Load the ground truth, which contains a subset of semantic joins, a subset of syntactic joins and a sample of the rest of joins.\n",
    "- Merge it with the distances. That is, for each selected pair \"add\" the distances between the metrics of their respective profiles\n",
    "- Remove unnecessary columns for the models (e.g. dataset and attribute names)\n",
    "- Transform categorical variables into dummies\n",
    "\n",
    "**Important**: the `ground_truth_models.csv` file contains all the semantic and syntactic joins detected in the data lake + a sample of joins that do not have a relationship (i.e. containment < 0.1 and no semantic link), indicated with a *null* value in the relationships cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "error",
     "timestamp": 1753704098205,
     "user": {
      "displayName": "Marc Maynou Yelamos",
      "userId": "15390060321136749570"
     },
     "user_tz": -120
    },
    "id": "FZN3haMUrqTs",
    "outputId": "7aed1fd3-ce0c-4996-fcd5-a3110d5929a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of syntactic joins: 2703\n",
      "Number of semantic joins: 1701\n",
      "Number of unrelated pairs: 18206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>containment</th>\n",
       "      <th>cardinality_proportion</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>multiset_jaccard</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22610.000000</td>\n",
       "      <td>2.261000e+04</td>\n",
       "      <td>22610.000000</td>\n",
       "      <td>22610.000000</td>\n",
       "      <td>22610.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.107225</td>\n",
       "      <td>2.154501e-01</td>\n",
       "      <td>0.043204</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.004229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.242172</td>\n",
       "      <td>2.893796e-01</td>\n",
       "      <td>0.149750</td>\n",
       "      <td>0.050149</td>\n",
       "      <td>0.033486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.251912e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.015228e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.189559e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        containment  cardinality_proportion       jaccard  multiset_jaccard  \\\n",
       "count  22610.000000            2.261000e+04  22610.000000      22610.000000   \n",
       "mean       0.107225            2.154501e-01      0.043204          0.010597   \n",
       "std        0.242172            2.893796e-01      0.149750          0.050149   \n",
       "min        0.000000            4.251912e-07      0.000000          0.000000   \n",
       "25%        0.000000            1.015228e-02      0.000000          0.000000   \n",
       "50%        0.000000            6.189559e-02      0.000000          0.000000   \n",
       "75%        0.045455            3.333333e-01      0.002380          0.000219   \n",
       "max        1.000000            1.000000e+00      1.000000          0.500000   \n",
       "\n",
       "            quality  \n",
       "count  22610.000000  \n",
       "mean       0.004229  \n",
       "std        0.033486  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000002  \n",
       "max        0.494872  "
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ground_truth = pd.read_csv(f'D:/Work/research/freyja/drive_repo/data/ground_truths/ground_truth_models.csv')\n",
    "ground_truth = pd.read_csv(f'C:/Projects/freyja_plus_more/distances/ground_truth_models.csv')\n",
    "ground_truth['relationship'] = ground_truth['relationship'].fillna('unrelated') # Pairs that are neither semantic or syntactic have a NaN. We change it by unrelated to prevent problems.\n",
    "\n",
    "count_syntactic = (ground_truth['relationship'] == 'syntactic').sum()\n",
    "count_semantic = (ground_truth['relationship'] == 'semantic').sum()\n",
    "count_unrelated = (ground_truth['relationship'] == 'unrelated').sum()\n",
    "\n",
    "print(f\"Number of syntactic joins: {count_syntactic}\")\n",
    "print(f\"Number of semantic joins: {count_semantic}\")\n",
    "print(f\"Number of unrelated pairs: {count_unrelated}\")\n",
    "\n",
    "ground_truth.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_name</th>\n",
       "      <th>att_name</th>\n",
       "      <th>ds_name_2</th>\n",
       "      <th>att_name_2</th>\n",
       "      <th>relationship</th>\n",
       "      <th>containment</th>\n",
       "      <th>cardinality_proportion</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>multiset_jaccard</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>world_country.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>1.381513e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Distributions_data_2016.csv</td>\n",
       "      <td>demographics</td>\n",
       "      <td>Tech_sector_diversity_demographics_2016.csv</td>\n",
       "      <td>raceEthnicity</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.041278e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA_cars_datasets.csv</td>\n",
       "      <td>country</td>\n",
       "      <td>world_country.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>4.659192e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World_countries_env_vars.csv</td>\n",
       "      <td>Country</td>\n",
       "      <td>world_city.csv</td>\n",
       "      <td>District</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.053498</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>6.364830e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>books_updated.csv</td>\n",
       "      <td>languageCode</td>\n",
       "      <td>countries_metadatacountries.csv</td>\n",
       "      <td>CountryCode</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>1.381148e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22605</th>\n",
       "      <td>pte_sulfo.csv</td>\n",
       "      <td>Set</td>\n",
       "      <td>AdventureWorks2014_shift.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22606</th>\n",
       "      <td>dataSpotifyClass.csv</td>\n",
       "      <td>song_title</td>\n",
       "      <td>netflix_titles.csv</td>\n",
       "      <td>description</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22607</th>\n",
       "      <td>pte_methoxy.csv</td>\n",
       "      <td>Arg0</td>\n",
       "      <td>countries_data.csv</td>\n",
       "      <td>1997</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22608</th>\n",
       "      <td>student-mat.csv</td>\n",
       "      <td>internet</td>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22609</th>\n",
       "      <td>ipums_la_98-small.csv</td>\n",
       "      <td>schltype</td>\n",
       "      <td>financial_order.csv</td>\n",
       "      <td>ksymbol</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>4.544962e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22610 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ds_name      att_name  \\\n",
       "0      AdventureWorks2014_stateprovince.csv          Name   \n",
       "1               Distributions_data_2016.csv  demographics   \n",
       "2                     USA_cars_datasets.csv       country   \n",
       "3              World_countries_env_vars.csv       Country   \n",
       "4                         books_updated.csv  languageCode   \n",
       "...                                     ...           ...   \n",
       "22605                         pte_sulfo.csv           Set   \n",
       "22606                  dataSpotifyClass.csv    song_title   \n",
       "22607                       pte_methoxy.csv          Arg0   \n",
       "22608                       student-mat.csv      internet   \n",
       "22609                 ipums_la_98-small.csv      schltype   \n",
       "\n",
       "                                         ds_name_2     att_name_2  \\\n",
       "0                                world_country.csv           Name   \n",
       "1      Tech_sector_diversity_demographics_2016.csv  raceEthnicity   \n",
       "2                                world_country.csv           Name   \n",
       "3                                   world_city.csv       District   \n",
       "4                  countries_metadatacountries.csv    CountryCode   \n",
       "...                                            ...            ...   \n",
       "22605                 AdventureWorks2014_shift.csv           Name   \n",
       "22606                           netflix_titles.csv    description   \n",
       "22607                           countries_data.csv           1997   \n",
       "22608         AdventureWorks2014_stateprovince.csv           Name   \n",
       "22609                          financial_order.csv        ksymbol   \n",
       "\n",
       "      relationship  containment  cardinality_proportion   jaccard  \\\n",
       "0        unrelated     0.044199                0.757322  0.019417   \n",
       "1        syntactic     0.230769                0.461538  0.187500   \n",
       "2         semantic     0.500000                0.008368  0.004167   \n",
       "3        unrelated     0.053498                0.177892  0.006250   \n",
       "4        syntactic     0.360000                0.101215  0.034091   \n",
       "...            ...          ...                     ...       ...   \n",
       "22605    unrelated     0.000000                0.120000  0.000000   \n",
       "22606    unrelated     0.000000                0.313414  0.000000   \n",
       "22607    unrelated     0.000000                0.004015  0.000000   \n",
       "22608    unrelated     0.000000                0.011050  0.000000   \n",
       "22609    unrelated     0.000000                0.750000  0.125000   \n",
       "\n",
       "       multiset_jaccard       quality  \n",
       "0              0.019048  1.381513e-03  \n",
       "1              0.000186  1.041278e-05  \n",
       "2              0.000365  4.659192e-07  \n",
       "3              0.002314  6.364830e-05  \n",
       "4              0.000878  1.381148e-05  \n",
       "...                 ...           ...  \n",
       "22605          0.000000  0.000000e+00  \n",
       "22606          0.000000  0.000000e+00  \n",
       "22607          0.000000  0.000000e+00  \n",
       "22608          0.000000  0.000000e+00  \n",
       "22609          0.000072  4.544962e-06  \n",
       "\n",
       "[22610 rows x 10 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 50) \n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardinality</th>\n",
       "      <th>uniqueness</th>\n",
       "      <th>entropy</th>\n",
       "      <th>incompleteness</th>\n",
       "      <th>frequency_avg</th>\n",
       "      <th>frequency_min</th>\n",
       "      <th>frequency_max</th>\n",
       "      <th>frequency_sd</th>\n",
       "      <th>val_pct_min</th>\n",
       "      <th>val_pct_max</th>\n",
       "      <th>val_pct_std</th>\n",
       "      <th>constancy</th>\n",
       "      <th>freq_word_containment</th>\n",
       "      <th>freq_word_soundex_containment</th>\n",
       "      <th>frequency_1qo</th>\n",
       "      <th>frequency_2qo</th>\n",
       "      <th>frequency_3qo</th>\n",
       "      <th>frequency_4qo</th>\n",
       "      <th>frequency_5qo</th>\n",
       "      <th>frequency_6qo</th>\n",
       "      <th>frequency_7qo</th>\n",
       "      <th>len_max_word</th>\n",
       "      <th>len_min_word</th>\n",
       "      <th>len_avg_word</th>\n",
       "      <th>words_cnt_max</th>\n",
       "      <th>words_cnt_min</th>\n",
       "      <th>words_cnt_avg</th>\n",
       "      <th>number_words</th>\n",
       "      <th>words_cnt_sd</th>\n",
       "      <th>is_empty</th>\n",
       "      <th>is_binary</th>\n",
       "      <th>frequency_iqr</th>\n",
       "      <th>first_word</th>\n",
       "      <th>last_word</th>\n",
       "      <th>name_dist</th>\n",
       "      <th>attribute_name_1</th>\n",
       "      <th>dataset_name_1</th>\n",
       "      <th>attribute_name_2</th>\n",
       "      <th>dataset_name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.108842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.391746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038572</td>\n",
       "      <td>-0.080854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002658</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>-0.040542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Name</td>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>world_country.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.135553</td>\n",
       "      <td>0.312151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462026</td>\n",
       "      <td>0.760268</td>\n",
       "      <td>0.130824</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.033880</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>1.044655</td>\n",
       "      <td>0.505290</td>\n",
       "      <td>1.680113</td>\n",
       "      <td>-0.020214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016396</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>-0.055985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>demographics</td>\n",
       "      <td>Distributions_data_2016.csv</td>\n",
       "      <td>raceEthnicity</td>\n",
       "      <td>Tech_sector_diversity_demographics_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006587</td>\n",
       "      <td>-0.999200</td>\n",
       "      <td>-2.136850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470250</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.265810</td>\n",
       "      <td>0.637923</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.497199</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>-0.457037</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.651360</td>\n",
       "      <td>-0.121281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>-0.141034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>country</td>\n",
       "      <td>USA_cars_datasets.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>world_country.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.031214</td>\n",
       "      <td>0.665114</td>\n",
       "      <td>-0.391069</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007470</td>\n",
       "      <td>-0.002878</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>-0.013291</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>-0.013291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>-0.457037</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.095685</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>-0.052841</td>\n",
       "      <td>0.053482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>Country</td>\n",
       "      <td>World_countries_env_vars.csv</td>\n",
       "      <td>District</td>\n",
       "      <td>world_city.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006171</td>\n",
       "      <td>-0.997500</td>\n",
       "      <td>-1.825795</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.133952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676529</td>\n",
       "      <td>0.660607</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>0.630051</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>0.630051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.001949</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.130582</td>\n",
       "      <td>-0.252645</td>\n",
       "      <td>0.091715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>languageCode</td>\n",
       "      <td>books_updated.csv</td>\n",
       "      <td>CountryCode</td>\n",
       "      <td>countries_metadatacountries.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22605</th>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>2.219892</td>\n",
       "      <td>8.084643</td>\n",
       "      <td>5.951487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>Set</td>\n",
       "      <td>pte_sulfo.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>AdventureWorks2014_shift.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22606</th>\n",
       "      <td>-0.118797</td>\n",
       "      <td>-0.030943</td>\n",
       "      <td>-0.458812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>-0.587618</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.035152</td>\n",
       "      <td>-0.525552</td>\n",
       "      <td>-14.027789</td>\n",
       "      <td>-1.844182</td>\n",
       "      <td>-1.519398</td>\n",
       "      <td>-0.086287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "      <td>song_title</td>\n",
       "      <td>dataSpotifyClass.csv</td>\n",
       "      <td>description</td>\n",
       "      <td>netflix_titles.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22607</th>\n",
       "      <td>-0.241318</td>\n",
       "      <td>0.148744</td>\n",
       "      <td>-0.609571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.022797</td>\n",
       "      <td>-0.052781</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>-0.378163</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>-0.378163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>-1.240528</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.264055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Arg0</td>\n",
       "      <td>pte_methoxy.csv</td>\n",
       "      <td>1997</td>\n",
       "      <td>countries_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22608</th>\n",
       "      <td>-0.004975</td>\n",
       "      <td>-0.994937</td>\n",
       "      <td>-1.858861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074012</td>\n",
       "      <td>0.040177</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.332911</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>-1.044655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.642904</td>\n",
       "      <td>-0.040427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.040355</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>-0.100492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665823</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>internet</td>\n",
       "      <td>student-mat.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22609</th>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.152442</td>\n",
       "      <td>0.496849</td>\n",
       "      <td>-0.206907</td>\n",
       "      <td>-0.136601</td>\n",
       "      <td>-0.181190</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>-0.036665</td>\n",
       "      <td>-0.300168</td>\n",
       "      <td>-0.097639</td>\n",
       "      <td>-0.300168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036665</td>\n",
       "      <td>-0.036665</td>\n",
       "      <td>-0.049214</td>\n",
       "      <td>-0.049214</td>\n",
       "      <td>-0.077803</td>\n",
       "      <td>0.130213</td>\n",
       "      <td>-0.300168</td>\n",
       "      <td>0.848782</td>\n",
       "      <td>2.273806</td>\n",
       "      <td>1.641934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166878</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>schltype</td>\n",
       "      <td>ipums_la_98-small.csv</td>\n",
       "      <td>ksymbol</td>\n",
       "      <td>financial_order.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22610 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cardinality  uniqueness   entropy  incompleteness  frequency_avg  \\\n",
       "0        -0.001612    0.000000 -0.108842        0.000000       0.000000   \n",
       "1         0.000195   -0.135553  0.312151        0.000000       0.462026   \n",
       "2        -0.006587   -0.999200 -2.136850        0.000000       0.470250   \n",
       "3        -0.031214    0.665114 -0.391069       -0.000981      -0.000747   \n",
       "4        -0.006171   -0.997500 -1.825795        0.108400       0.133952   \n",
       "...            ...         ...       ...             ...            ...   \n",
       "22605     0.000611    0.000000  0.830221        0.000000       0.000000   \n",
       "22606    -0.118797   -0.030943 -0.458812        0.000000       0.000012   \n",
       "22607    -0.241318    0.148744 -0.609571        0.000000      -0.000221   \n",
       "22608    -0.004975   -0.994937 -1.858861        0.000000       0.074012   \n",
       "22609    -0.000028   -0.000217 -0.152442        0.496849      -0.206907   \n",
       "\n",
       "       frequency_min  frequency_max  frequency_sd  val_pct_min  val_pct_max  \\\n",
       "0           0.000000       0.000000      0.000000     0.001341     0.001341   \n",
       "1           0.760268       0.130824     -0.000765    -0.013986    -0.104895   \n",
       "2           0.003709       0.265810      0.637923    -0.001383     0.993015   \n",
       "3           0.000000      -0.007470     -0.002878     0.003870    -0.013291   \n",
       "4           0.000000       0.676529      0.660607    -0.003949     0.630051   \n",
       "...              ...            ...           ...          ...          ...   \n",
       "22605       0.000000       0.000000      0.000000    -0.293333    -0.293333   \n",
       "22606       0.000000       0.000000      0.000074     0.000335     0.001006   \n",
       "22607       0.000000      -1.022797     -0.052781     0.016617    -0.378163   \n",
       "22608       0.040177       0.035000      0.067515     0.161564     0.827387   \n",
       "22609      -0.136601      -0.181190     -0.271133    -0.036665    -0.300168   \n",
       "\n",
       "       val_pct_std  constancy  freq_word_containment  \\\n",
       "0         0.000000   0.001341                    0.1   \n",
       "1        -0.033880  -0.104895                    0.2   \n",
       "2         0.497199   0.993015                    0.0   \n",
       "3        -0.001374  -0.013291                    0.0   \n",
       "4         0.128668   0.630051                    0.0   \n",
       "...            ...        ...                    ...   \n",
       "22605     0.000000  -0.293333                    0.0   \n",
       "22606     0.000085   0.001006                    0.0   \n",
       "22607     0.010038  -0.378163                    0.0   \n",
       "22608     0.332911   0.827387                    0.0   \n",
       "22609    -0.097639  -0.300168                    0.0   \n",
       "\n",
       "       freq_word_soundex_containment  frequency_1qo  frequency_2qo  \\\n",
       "0                           0.250000       0.001341       0.001341   \n",
       "1                           0.428571      -0.013986      -0.104895   \n",
       "2                           0.000000      -0.001383      -0.001383   \n",
       "3                           0.125000       0.003870       0.003870   \n",
       "4                           0.125000      -0.003949      -0.003949   \n",
       "...                              ...            ...            ...   \n",
       "22605                       0.000000      -0.293333      -0.293333   \n",
       "22606                       0.000000       0.000335       0.000335   \n",
       "22607                       0.000000       0.016617       0.016617   \n",
       "22608                       0.000000       0.161564       0.161564   \n",
       "22609                       0.000000      -0.036665      -0.036665   \n",
       "\n",
       "       frequency_3qo  frequency_4qo  frequency_5qo  frequency_6qo  \\\n",
       "0           0.001341       0.001341       0.001341       0.001341   \n",
       "1          -0.104895      -0.104895      -0.104895      -0.104895   \n",
       "2          -0.001383      -0.001383       0.993015       0.993015   \n",
       "3           0.003870       0.003870       0.003625       0.003380   \n",
       "4          -0.003749      -0.003449      -0.003349      -0.001949   \n",
       "...              ...            ...            ...            ...   \n",
       "22605      -0.293333      -0.293333      -0.293333      -0.293333   \n",
       "22606       0.000335       0.000335       0.000335       0.000335   \n",
       "22607       0.016617       0.033283       0.033283       0.033283   \n",
       "22608       0.161564       0.161564       0.827387       0.827387   \n",
       "22609      -0.049214      -0.049214      -0.077803       0.130213   \n",
       "\n",
       "       frequency_7qo  len_max_word  len_min_word  len_avg_word  words_cnt_max  \\\n",
       "0           0.001341      0.391746      0.000000     -0.038572      -0.080854   \n",
       "1          -0.104895      1.044655      0.505290      1.680113      -0.020214   \n",
       "2           0.993015     -0.457037      0.252645     -0.651360      -0.121281   \n",
       "3           0.002889     -0.457037      0.252645     -0.095685       0.020214   \n",
       "4           0.002351      0.130582     -0.252645      0.091715       0.000000   \n",
       "...              ...           ...           ...           ...            ...   \n",
       "22605      -0.293333      2.219892      8.084643      5.951487       0.000000   \n",
       "22606       0.000335     -0.587618      0.252645     -0.035152      -0.525552   \n",
       "22607       0.033283     -1.240528      0.252645     -0.264055       0.000000   \n",
       "22608       0.827387     -1.044655      0.000000     -0.642904      -0.040427   \n",
       "22609      -0.300168      0.848782      2.273806      1.641934       0.000000   \n",
       "\n",
       "       words_cnt_min  words_cnt_avg  number_words  words_cnt_sd  is_empty  \\\n",
       "0           0.000000      -0.002658     -0.000977     -0.040542         0   \n",
       "1           0.000000      -0.016396      0.171629     -0.055985         0   \n",
       "2           0.000000      -0.043013      0.023034     -0.141034         0   \n",
       "3           0.000000       0.019129     -0.052841      0.053482         0   \n",
       "4           0.000000       0.000000      0.093049      0.000000         0   \n",
       "...              ...            ...           ...           ...       ...   \n",
       "22605       0.000000       0.000000      0.000236      0.000000         0   \n",
       "22606     -14.027789      -1.844182     -1.519398     -0.086287         0   \n",
       "22607       0.000000       0.000000     -0.214649      0.000000         0   \n",
       "22608       0.000000      -0.040355      0.001428     -0.100492         0   \n",
       "22609       0.000000       0.000000     -0.031353      0.000000         0   \n",
       "\n",
       "       is_binary  frequency_iqr  first_word  last_word  name_dist  \\\n",
       "0              0       0.000000           8          7          0   \n",
       "1              0       0.000000           4         13         12   \n",
       "2              1       0.994398           8          7          7   \n",
       "3              0      -0.000490          14          8          7   \n",
       "4              0       0.002000           2          2          8   \n",
       "...          ...            ...         ...        ...        ...   \n",
       "22605          0       0.000000          39         36          4   \n",
       "22606          0       0.000000         104        135          9   \n",
       "22607          0       0.016667          22          2          4   \n",
       "22608          1       0.665823           3          5          7   \n",
       "22609          0       0.166878          19         12          8   \n",
       "\n",
       "      attribute_name_1                        dataset_name_1 attribute_name_2  \\\n",
       "0                 Name  AdventureWorks2014_stateprovince.csv             Name   \n",
       "1         demographics           Distributions_data_2016.csv    raceEthnicity   \n",
       "2              country                 USA_cars_datasets.csv             Name   \n",
       "3              Country          World_countries_env_vars.csv         District   \n",
       "4         languageCode                     books_updated.csv      CountryCode   \n",
       "...                ...                                   ...              ...   \n",
       "22605              Set                         pte_sulfo.csv             Name   \n",
       "22606       song_title                  dataSpotifyClass.csv      description   \n",
       "22607             Arg0                       pte_methoxy.csv             1997   \n",
       "22608         internet                       student-mat.csv             Name   \n",
       "22609         schltype                 ipums_la_98-small.csv          ksymbol   \n",
       "\n",
       "                                    dataset_name_2  \n",
       "0                                world_country.csv  \n",
       "1      Tech_sector_diversity_demographics_2016.csv  \n",
       "2                                world_country.csv  \n",
       "3                                   world_city.csv  \n",
       "4                  countries_metadatacountries.csv  \n",
       "...                                            ...  \n",
       "22605                 AdventureWorks2014_shift.csv  \n",
       "22606                           netflix_titles.csv  \n",
       "22607                           countries_data.csv  \n",
       "22608         AdventureWorks2014_stateprovince.csv  \n",
       "22609                          financial_order.csv  \n",
       "\n",
       "[22610 rows x 39 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distances = pd.read_csv(f'C:/Projects/freyja_plus_more/distances/distances_model_prenormalized_all.csv')\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 19450,
     "status": "ok",
     "timestamp": 1736505249702,
     "user": {
      "displayName": "Marc Maynou Yelamos",
      "userId": "15390060321136749570"
     },
     "user_tz": -60
    },
    "id": "iXd8o58DTDUz",
    "outputId": "6edf9e8f-797c-4c1c-d4ae-477c74f60857"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_name</th>\n",
       "      <th>att_name</th>\n",
       "      <th>ds_name_2</th>\n",
       "      <th>att_name_2</th>\n",
       "      <th>relationship</th>\n",
       "      <th>containment</th>\n",
       "      <th>cardinality_proportion</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>multiset_jaccard</th>\n",
       "      <th>quality</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>uniqueness</th>\n",
       "      <th>entropy</th>\n",
       "      <th>incompleteness</th>\n",
       "      <th>frequency_avg</th>\n",
       "      <th>frequency_min</th>\n",
       "      <th>frequency_max</th>\n",
       "      <th>frequency_sd</th>\n",
       "      <th>val_pct_min</th>\n",
       "      <th>val_pct_max</th>\n",
       "      <th>val_pct_std</th>\n",
       "      <th>constancy</th>\n",
       "      <th>freq_word_containment</th>\n",
       "      <th>freq_word_soundex_containment</th>\n",
       "      <th>frequency_1qo</th>\n",
       "      <th>frequency_2qo</th>\n",
       "      <th>frequency_3qo</th>\n",
       "      <th>frequency_4qo</th>\n",
       "      <th>frequency_5qo</th>\n",
       "      <th>frequency_6qo</th>\n",
       "      <th>frequency_7qo</th>\n",
       "      <th>len_max_word</th>\n",
       "      <th>len_min_word</th>\n",
       "      <th>len_avg_word</th>\n",
       "      <th>words_cnt_max</th>\n",
       "      <th>words_cnt_min</th>\n",
       "      <th>words_cnt_avg</th>\n",
       "      <th>number_words</th>\n",
       "      <th>words_cnt_sd</th>\n",
       "      <th>is_empty</th>\n",
       "      <th>is_binary</th>\n",
       "      <th>frequency_iqr</th>\n",
       "      <th>first_word</th>\n",
       "      <th>last_word</th>\n",
       "      <th>name_dist</th>\n",
       "      <th>attribute_name_1</th>\n",
       "      <th>dataset_name_1</th>\n",
       "      <th>attribute_name_2</th>\n",
       "      <th>dataset_name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>world_country.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>1.381513e-03</td>\n",
       "      <td>-0.001612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.108842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.391746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038572</td>\n",
       "      <td>-0.080854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002658</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>-0.040542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Name</td>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>world_country.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Distributions_data_2016.csv</td>\n",
       "      <td>demographics</td>\n",
       "      <td>Tech_sector_diversity_demographics_2016.csv</td>\n",
       "      <td>raceEthnicity</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.041278e-05</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.135553</td>\n",
       "      <td>0.312151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462026</td>\n",
       "      <td>0.760268</td>\n",
       "      <td>0.130824</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.033880</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>1.044655</td>\n",
       "      <td>0.505290</td>\n",
       "      <td>1.680113</td>\n",
       "      <td>-0.020214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016396</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>-0.055985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>demographics</td>\n",
       "      <td>Distributions_data_2016.csv</td>\n",
       "      <td>raceEthnicity</td>\n",
       "      <td>Tech_sector_diversity_demographics_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA_cars_datasets.csv</td>\n",
       "      <td>country</td>\n",
       "      <td>world_country.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>4.659192e-07</td>\n",
       "      <td>-0.006587</td>\n",
       "      <td>-0.999200</td>\n",
       "      <td>-2.136850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470250</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.265810</td>\n",
       "      <td>0.637923</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.497199</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>0.993015</td>\n",
       "      <td>-0.457037</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.651360</td>\n",
       "      <td>-0.121281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>-0.141034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>country</td>\n",
       "      <td>USA_cars_datasets.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>world_country.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World_countries_env_vars.csv</td>\n",
       "      <td>Country</td>\n",
       "      <td>world_city.csv</td>\n",
       "      <td>District</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.053498</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>6.364830e-05</td>\n",
       "      <td>-0.031214</td>\n",
       "      <td>0.665114</td>\n",
       "      <td>-0.391069</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007470</td>\n",
       "      <td>-0.002878</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>-0.013291</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>-0.013291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>-0.457037</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.095685</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>-0.052841</td>\n",
       "      <td>0.053482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>Country</td>\n",
       "      <td>World_countries_env_vars.csv</td>\n",
       "      <td>District</td>\n",
       "      <td>world_city.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>books_updated.csv</td>\n",
       "      <td>languageCode</td>\n",
       "      <td>countries_metadatacountries.csv</td>\n",
       "      <td>CountryCode</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>1.381148e-05</td>\n",
       "      <td>-0.006171</td>\n",
       "      <td>-0.997500</td>\n",
       "      <td>-1.825795</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.133952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676529</td>\n",
       "      <td>0.660607</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>0.630051</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>0.630051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.001949</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.130582</td>\n",
       "      <td>-0.252645</td>\n",
       "      <td>0.091715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>languageCode</td>\n",
       "      <td>books_updated.csv</td>\n",
       "      <td>CountryCode</td>\n",
       "      <td>countries_metadatacountries.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22607</th>\n",
       "      <td>pte_sulfo.csv</td>\n",
       "      <td>Set</td>\n",
       "      <td>AdventureWorks2014_shift.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>-0.293333</td>\n",
       "      <td>2.219892</td>\n",
       "      <td>8.084643</td>\n",
       "      <td>5.951487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>Set</td>\n",
       "      <td>pte_sulfo.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>AdventureWorks2014_shift.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22608</th>\n",
       "      <td>dataSpotifyClass.csv</td>\n",
       "      <td>song_title</td>\n",
       "      <td>netflix_titles.csv</td>\n",
       "      <td>description</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.118797</td>\n",
       "      <td>-0.030943</td>\n",
       "      <td>-0.458812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>-0.587618</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.035152</td>\n",
       "      <td>-0.525552</td>\n",
       "      <td>-14.027789</td>\n",
       "      <td>-1.844182</td>\n",
       "      <td>-1.519398</td>\n",
       "      <td>-0.086287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "      <td>song_title</td>\n",
       "      <td>dataSpotifyClass.csv</td>\n",
       "      <td>description</td>\n",
       "      <td>netflix_titles.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22609</th>\n",
       "      <td>pte_methoxy.csv</td>\n",
       "      <td>Arg0</td>\n",
       "      <td>countries_data.csv</td>\n",
       "      <td>1997</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.241318</td>\n",
       "      <td>0.148744</td>\n",
       "      <td>-0.609571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.022797</td>\n",
       "      <td>-0.052781</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>-0.378163</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>-0.378163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>-1.240528</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>-0.264055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Arg0</td>\n",
       "      <td>pte_methoxy.csv</td>\n",
       "      <td>1997</td>\n",
       "      <td>countries_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22610</th>\n",
       "      <td>student-mat.csv</td>\n",
       "      <td>internet</td>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.004975</td>\n",
       "      <td>-0.994937</td>\n",
       "      <td>-1.858861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074012</td>\n",
       "      <td>0.040177</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.332911</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.161564</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>0.827387</td>\n",
       "      <td>-1.044655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.642904</td>\n",
       "      <td>-0.040427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.040355</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>-0.100492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665823</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>internet</td>\n",
       "      <td>student-mat.csv</td>\n",
       "      <td>Name</td>\n",
       "      <td>AdventureWorks2014_stateprovince.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22611</th>\n",
       "      <td>ipums_la_98-small.csv</td>\n",
       "      <td>schltype</td>\n",
       "      <td>financial_order.csv</td>\n",
       "      <td>ksymbol</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>4.544962e-06</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.152442</td>\n",
       "      <td>0.496849</td>\n",
       "      <td>-0.206907</td>\n",
       "      <td>-0.136601</td>\n",
       "      <td>-0.181190</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>-0.036665</td>\n",
       "      <td>-0.300168</td>\n",
       "      <td>-0.097639</td>\n",
       "      <td>-0.300168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036665</td>\n",
       "      <td>-0.036665</td>\n",
       "      <td>-0.049214</td>\n",
       "      <td>-0.049214</td>\n",
       "      <td>-0.077803</td>\n",
       "      <td>0.130213</td>\n",
       "      <td>-0.300168</td>\n",
       "      <td>0.848782</td>\n",
       "      <td>2.273806</td>\n",
       "      <td>1.641934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166878</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>schltype</td>\n",
       "      <td>ipums_la_98-small.csv</td>\n",
       "      <td>ksymbol</td>\n",
       "      <td>financial_order.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22612 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ds_name      att_name  \\\n",
       "0      AdventureWorks2014_stateprovince.csv          Name   \n",
       "1               Distributions_data_2016.csv  demographics   \n",
       "2                     USA_cars_datasets.csv       country   \n",
       "3              World_countries_env_vars.csv       Country   \n",
       "4                         books_updated.csv  languageCode   \n",
       "...                                     ...           ...   \n",
       "22607                         pte_sulfo.csv           Set   \n",
       "22608                  dataSpotifyClass.csv    song_title   \n",
       "22609                       pte_methoxy.csv          Arg0   \n",
       "22610                       student-mat.csv      internet   \n",
       "22611                 ipums_la_98-small.csv      schltype   \n",
       "\n",
       "                                         ds_name_2     att_name_2  \\\n",
       "0                                world_country.csv           Name   \n",
       "1      Tech_sector_diversity_demographics_2016.csv  raceEthnicity   \n",
       "2                                world_country.csv           Name   \n",
       "3                                   world_city.csv       District   \n",
       "4                  countries_metadatacountries.csv    CountryCode   \n",
       "...                                            ...            ...   \n",
       "22607                 AdventureWorks2014_shift.csv           Name   \n",
       "22608                           netflix_titles.csv    description   \n",
       "22609                           countries_data.csv           1997   \n",
       "22610         AdventureWorks2014_stateprovince.csv           Name   \n",
       "22611                          financial_order.csv        ksymbol   \n",
       "\n",
       "      relationship  containment  cardinality_proportion   jaccard  \\\n",
       "0        unrelated     0.044199                0.757322  0.019417   \n",
       "1        syntactic     0.230769                0.461538  0.187500   \n",
       "2         semantic     0.500000                0.008368  0.004167   \n",
       "3        unrelated     0.053498                0.177892  0.006250   \n",
       "4        syntactic     0.360000                0.101215  0.034091   \n",
       "...            ...          ...                     ...       ...   \n",
       "22607    unrelated     0.000000                0.120000  0.000000   \n",
       "22608    unrelated     0.000000                0.313414  0.000000   \n",
       "22609    unrelated     0.000000                0.004015  0.000000   \n",
       "22610    unrelated     0.000000                0.011050  0.000000   \n",
       "22611    unrelated     0.000000                0.750000  0.125000   \n",
       "\n",
       "       multiset_jaccard       quality  cardinality  uniqueness   entropy  \\\n",
       "0              0.019048  1.381513e-03    -0.001612    0.000000 -0.108842   \n",
       "1              0.000186  1.041278e-05     0.000195   -0.135553  0.312151   \n",
       "2              0.000365  4.659192e-07    -0.006587   -0.999200 -2.136850   \n",
       "3              0.002314  6.364830e-05    -0.031214    0.665114 -0.391069   \n",
       "4              0.000878  1.381148e-05    -0.006171   -0.997500 -1.825795   \n",
       "...                 ...           ...          ...         ...       ...   \n",
       "22607          0.000000  0.000000e+00     0.000611    0.000000  0.830221   \n",
       "22608          0.000000  0.000000e+00    -0.118797   -0.030943 -0.458812   \n",
       "22609          0.000000  0.000000e+00    -0.241318    0.148744 -0.609571   \n",
       "22610          0.000000  0.000000e+00    -0.004975   -0.994937 -1.858861   \n",
       "22611          0.000072  4.544962e-06    -0.000028   -0.000217 -0.152442   \n",
       "\n",
       "       incompleteness  frequency_avg  frequency_min  frequency_max  \\\n",
       "0            0.000000       0.000000       0.000000       0.000000   \n",
       "1            0.000000       0.462026       0.760268       0.130824   \n",
       "2            0.000000       0.470250       0.003709       0.265810   \n",
       "3           -0.000981      -0.000747       0.000000      -0.007470   \n",
       "4            0.108400       0.133952       0.000000       0.676529   \n",
       "...               ...            ...            ...            ...   \n",
       "22607        0.000000       0.000000       0.000000       0.000000   \n",
       "22608        0.000000       0.000012       0.000000       0.000000   \n",
       "22609        0.000000      -0.000221       0.000000      -1.022797   \n",
       "22610        0.000000       0.074012       0.040177       0.035000   \n",
       "22611        0.496849      -0.206907      -0.136601      -0.181190   \n",
       "\n",
       "       frequency_sd  val_pct_min  val_pct_max  val_pct_std  constancy  \\\n",
       "0          0.000000     0.001341     0.001341     0.000000   0.001341   \n",
       "1         -0.000765    -0.013986    -0.104895    -0.033880  -0.104895   \n",
       "2          0.637923    -0.001383     0.993015     0.497199   0.993015   \n",
       "3         -0.002878     0.003870    -0.013291    -0.001374  -0.013291   \n",
       "4          0.660607    -0.003949     0.630051     0.128668   0.630051   \n",
       "...             ...          ...          ...          ...        ...   \n",
       "22607      0.000000    -0.293333    -0.293333     0.000000  -0.293333   \n",
       "22608      0.000074     0.000335     0.001006     0.000085   0.001006   \n",
       "22609     -0.052781     0.016617    -0.378163     0.010038  -0.378163   \n",
       "22610      0.067515     0.161564     0.827387     0.332911   0.827387   \n",
       "22611     -0.271133    -0.036665    -0.300168    -0.097639  -0.300168   \n",
       "\n",
       "       freq_word_containment  freq_word_soundex_containment  frequency_1qo  \\\n",
       "0                        0.1                       0.250000       0.001341   \n",
       "1                        0.2                       0.428571      -0.013986   \n",
       "2                        0.0                       0.000000      -0.001383   \n",
       "3                        0.0                       0.125000       0.003870   \n",
       "4                        0.0                       0.125000      -0.003949   \n",
       "...                      ...                            ...            ...   \n",
       "22607                    0.0                       0.000000      -0.293333   \n",
       "22608                    0.0                       0.000000       0.000335   \n",
       "22609                    0.0                       0.000000       0.016617   \n",
       "22610                    0.0                       0.000000       0.161564   \n",
       "22611                    0.0                       0.000000      -0.036665   \n",
       "\n",
       "       frequency_2qo  frequency_3qo  frequency_4qo  frequency_5qo  \\\n",
       "0           0.001341       0.001341       0.001341       0.001341   \n",
       "1          -0.104895      -0.104895      -0.104895      -0.104895   \n",
       "2          -0.001383      -0.001383      -0.001383       0.993015   \n",
       "3           0.003870       0.003870       0.003870       0.003625   \n",
       "4          -0.003949      -0.003749      -0.003449      -0.003349   \n",
       "...              ...            ...            ...            ...   \n",
       "22607      -0.293333      -0.293333      -0.293333      -0.293333   \n",
       "22608       0.000335       0.000335       0.000335       0.000335   \n",
       "22609       0.016617       0.016617       0.033283       0.033283   \n",
       "22610       0.161564       0.161564       0.161564       0.827387   \n",
       "22611      -0.036665      -0.049214      -0.049214      -0.077803   \n",
       "\n",
       "       frequency_6qo  frequency_7qo  len_max_word  len_min_word  len_avg_word  \\\n",
       "0           0.001341       0.001341      0.391746      0.000000     -0.038572   \n",
       "1          -0.104895      -0.104895      1.044655      0.505290      1.680113   \n",
       "2           0.993015       0.993015     -0.457037      0.252645     -0.651360   \n",
       "3           0.003380       0.002889     -0.457037      0.252645     -0.095685   \n",
       "4          -0.001949       0.002351      0.130582     -0.252645      0.091715   \n",
       "...              ...            ...           ...           ...           ...   \n",
       "22607      -0.293333      -0.293333      2.219892      8.084643      5.951487   \n",
       "22608       0.000335       0.000335     -0.587618      0.252645     -0.035152   \n",
       "22609       0.033283       0.033283     -1.240528      0.252645     -0.264055   \n",
       "22610       0.827387       0.827387     -1.044655      0.000000     -0.642904   \n",
       "22611       0.130213      -0.300168      0.848782      2.273806      1.641934   \n",
       "\n",
       "       words_cnt_max  words_cnt_min  words_cnt_avg  number_words  \\\n",
       "0          -0.080854       0.000000      -0.002658     -0.000977   \n",
       "1          -0.020214       0.000000      -0.016396      0.171629   \n",
       "2          -0.121281       0.000000      -0.043013      0.023034   \n",
       "3           0.020214       0.000000       0.019129     -0.052841   \n",
       "4           0.000000       0.000000       0.000000      0.093049   \n",
       "...              ...            ...            ...           ...   \n",
       "22607       0.000000       0.000000       0.000000      0.000236   \n",
       "22608      -0.525552     -14.027789      -1.844182     -1.519398   \n",
       "22609       0.000000       0.000000       0.000000     -0.214649   \n",
       "22610      -0.040427       0.000000      -0.040355      0.001428   \n",
       "22611       0.000000       0.000000       0.000000     -0.031353   \n",
       "\n",
       "       words_cnt_sd  is_empty  is_binary  frequency_iqr  first_word  \\\n",
       "0         -0.040542         0          0       0.000000           8   \n",
       "1         -0.055985         0          0       0.000000           4   \n",
       "2         -0.141034         0          1       0.994398           8   \n",
       "3          0.053482         0          0      -0.000490          14   \n",
       "4          0.000000         0          0       0.002000           2   \n",
       "...             ...       ...        ...            ...         ...   \n",
       "22607      0.000000         0          0       0.000000          39   \n",
       "22608     -0.086287         0          0       0.000000         104   \n",
       "22609      0.000000         0          0       0.016667          22   \n",
       "22610     -0.100492         0          1       0.665823           3   \n",
       "22611      0.000000         0          0       0.166878          19   \n",
       "\n",
       "       last_word  name_dist attribute_name_1  \\\n",
       "0              7          0             Name   \n",
       "1             13         12     demographics   \n",
       "2              7          7          country   \n",
       "3              8          7          Country   \n",
       "4              2          8     languageCode   \n",
       "...          ...        ...              ...   \n",
       "22607         36          4              Set   \n",
       "22608        135          9       song_title   \n",
       "22609          2          4             Arg0   \n",
       "22610          5          7         internet   \n",
       "22611         12          8         schltype   \n",
       "\n",
       "                             dataset_name_1 attribute_name_2  \\\n",
       "0      AdventureWorks2014_stateprovince.csv             Name   \n",
       "1               Distributions_data_2016.csv    raceEthnicity   \n",
       "2                     USA_cars_datasets.csv             Name   \n",
       "3              World_countries_env_vars.csv         District   \n",
       "4                         books_updated.csv      CountryCode   \n",
       "...                                     ...              ...   \n",
       "22607                         pte_sulfo.csv             Name   \n",
       "22608                  dataSpotifyClass.csv      description   \n",
       "22609                       pte_methoxy.csv             1997   \n",
       "22610                       student-mat.csv             Name   \n",
       "22611                 ipums_la_98-small.csv          ksymbol   \n",
       "\n",
       "                                    dataset_name_2  \n",
       "0                                world_country.csv  \n",
       "1      Tech_sector_diversity_demographics_2016.csv  \n",
       "2                                world_country.csv  \n",
       "3                                   world_city.csv  \n",
       "4                  countries_metadatacountries.csv  \n",
       "...                                            ...  \n",
       "22607                 AdventureWorks2014_shift.csv  \n",
       "22608                           netflix_titles.csv  \n",
       "22609                           countries_data.csv  \n",
       "22610         AdventureWorks2014_stateprovince.csv  \n",
       "22611                          financial_order.csv  \n",
       "\n",
       "[22612 rows x 49 columns]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = pd.merge(ground_truth, distances, left_on=['ds_name', 'ds_name_2', 'att_name', 'att_name_2'], right_on=['dataset_name_1', 'dataset_name_2', 'attribute_name_1', 'attribute_name_2'])\n",
    "# joined_2 = pd.merge(ground_truth, distances, left_on=['ds_name', 'ds_name_2', 'att_name', 'att_name_2'], right_on=['dataset_name_2', 'dataset_name_1', 'attribute_name_2', 'attribute_name_1'])\n",
    "\n",
    "# merged = pd.concat([joined, joined_2], ignore_index=True)\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736505249702,
     "user": {
      "displayName": "Marc Maynou Yelamos",
      "userId": "15390060321136749570"
     },
     "user_tz": -60
    },
    "id": "QK2djoYXzHGg",
    "outputId": "9e06a7cb-e845-425b-f520-bcddf3c1a12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ds_name', 'att_name', 'ds_name_2', 'att_name_2', 'relationship',\n",
      "       'containment', 'cardinality_proportion', 'jaccard', 'multiset_jaccard',\n",
      "       'quality', 'cardinality', 'uniqueness', 'entropy', 'incompleteness',\n",
      "       'frequency_avg', 'frequency_min', 'frequency_max', 'frequency_sd',\n",
      "       'val_pct_min', 'val_pct_max', 'val_pct_std', 'constancy',\n",
      "       'freq_word_containment', 'freq_word_soundex_containment',\n",
      "       'frequency_1qo', 'frequency_2qo', 'frequency_3qo', 'frequency_4qo',\n",
      "       'frequency_5qo', 'frequency_6qo', 'frequency_7qo', 'len_max_word',\n",
      "       'len_min_word', 'len_avg_word', 'words_cnt_max', 'words_cnt_min',\n",
      "       'words_cnt_avg', 'number_words', 'words_cnt_sd', 'is_empty',\n",
      "       'is_binary', 'frequency_iqr', 'first_word', 'last_word', 'name_dist',\n",
      "       'attribute_name_1', 'dataset_name_1', 'attribute_name_2',\n",
      "       'dataset_name_2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(joined.columns)\n",
    "\n",
    "joined.drop(['ds_name', 'ds_name_2', 'att_name', 'att_name_2', \n",
    "             'relationship', 'containment', 'cardinality_proportion', 'jaccard', 'multiset_jaccard', \n",
    "             'dataset_name_1', 'attribute_name_1', 'dataset_name_2', 'attribute_name_2'],  \n",
    "             axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-hEqpoxmPwp"
   },
   "source": [
    "# Model selection\n",
    "\n",
    "Our goal is to define the best regressor model that can approximate the true value of the joinability metric defined ($MJ$ & $K$) by using profiles.\n",
    "\n",
    "We define four base models to do so, whose metrics vary. The first point of variation is the inclusion of \"datatypes\" metrics (i.e. semantic types/characteristics of each column: names, URIs, etc. / alphabetical, numerical etc. ). These metrics are the most time consuming to compute, which implies that the already lightweight profile-based approach can be made much faster. The second point of variation is the execution (or lack thereof) of feature selection tasks, which further reduce the number of features while, ideally, keeping, or improving, the evaluation scores.\n",
    "\n",
    "**Result**: for all models, the best performing regressor has been the Random Forest. Nonetheless, further testing with the benchmarks has shown that the Gradient Booster predictor (with no fine-tuning) works best. This might be due to overfitting produced by the Random Forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWZf8rrtp6oH"
   },
   "source": [
    "### Model evaluation methodology\n",
    "\n",
    "We want to define a regression model. To do so, we will employ 17 base regressors (listed below) evaluated over a 10-split CV (test size = 30%) and 4 different metrics, of which we will primarily focus on the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "id": "rSdayOnY9GuS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "split = ShuffleSplit(n_splits=10, test_size=0.3, random_state=211199)\n",
    "\n",
    "def scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return {\"R2\": r2_score(y, y_pred),\n",
    "            \"MAE\": mean_absolute_error(y, y_pred),\n",
    "            \"RMSE\": math.sqrt(mean_squared_error(y, y_pred)),\n",
    "            \"MedAE\": median_absolute_error(y, y_pred),}\n",
    "\n",
    "names = [\n",
    "    \"Linear Regression\",\n",
    "    \"Ridge Regression\",\n",
    "    \"Lasso Regression\",\n",
    "    \"ElasticNet Regression\",\n",
    "    \"Random Forests\",\n",
    "    \"Gradient Boosting\",\n",
    "    \"AdaBoost\",\n",
    "    \"Extra Trees\",\n",
    "    \"Histogram Gradient Boosting\",\n",
    "    \"XGBoosting\",\n",
    "    \"Light GBM\",\n",
    "    \"CatBoost\",\n",
    "    \"MLP Relu\",\n",
    "    \"MLP logistic\",\n",
    "    \"MLP Tanh\",\n",
    "    \"SVR Poly\",\n",
    "    \"SVR Rbf\"\n",
    "]\n",
    "\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    Ridge(random_state=211199),\n",
    "    Lasso(random_state=211199),\n",
    "    ElasticNet(random_state=211199),\n",
    "    RandomForestRegressor(random_state=211199, n_estimators=50),\n",
    "    GradientBoostingRegressor(random_state=211199, n_estimators=50),\n",
    "    AdaBoostRegressor(random_state=211199, n_estimators=50),\n",
    "    ExtraTreesRegressor(random_state=211199, n_estimators=50),\n",
    "    HistGradientBoostingRegressor(random_state=211199),\n",
    "    XGBRegressor(random_state=211199, n_estimators=50),\n",
    "    LGBMRegressor(random_state=211199, n_estimators=50, verbose=0),\n",
    "    CatBoostRegressor(random_state=211199, verbose=0),\n",
    "    MLPRegressor(random_state=211199, activation = 'relu'),\n",
    "    MLPRegressor(random_state=211199, activation = 'logistic'),\n",
    "    MLPRegressor(random_state=211199, activation = 'tanh'),\n",
    "    SVR(kernel=\"poly\"),\n",
    "    SVR(kernel=\"rbf\"),\n",
    "]\n",
    "\n",
    "def test_list_of_regressors(predictors, target, names, regressors):\n",
    "  for name, regressor in zip(names, regressors):\n",
    "    print(name)\n",
    "    test_regressor(regressor, predictors, target)\n",
    "\n",
    "def test_regressor(regressor, predictors, target):\n",
    "  scores = cross_validate(regressor, predictors, target, cv=split, scoring=scoring, verbose=0)\n",
    "  print(f\"Fit time: {scores['fit_time'].mean():.6f} | \"\n",
    "      f\"Score time: {scores['score_time'].mean():.6f}\")\n",
    "\n",
    "  print(f\"R2: {scores['test_R2'].mean():.6f} | \"\n",
    "      f\"MAE: {scores['test_MAE'].mean():.6f} | \"\n",
    "      f\"RMSE: {scores['test_RMSE'].mean():.6f} | \"\n",
    "      f\"MedAE: {scores['test_MedAE'].mean():.6f}\")\n",
    "  print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing, the regressors below are the ones that perform best in average. Hence, we define some functions to directly store the models associated with these base regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_names = [\n",
    "        \"gradient_boosting\",\n",
    "        \"extra_trees\",\n",
    "        \"xgboosting\",\n",
    "        \"catboost\"\n",
    "    ]\n",
    "\n",
    "best_regressors = [\n",
    "    GradientBoostingRegressor(random_state=211199, n_estimators=50),\n",
    "    ExtraTreesRegressor(random_state=211199, n_estimators=50),\n",
    "    XGBRegressor(random_state=211199, n_estimators=50),\n",
    "    CatBoostRegressor(random_state=211199, verbose=0),\n",
    "]\n",
    "\n",
    "def store_models(target, predictors, model_typology):\n",
    "    for name, regressor in tqdm(zip(best_names, best_regressors), total=len(best_names)):\n",
    "        regressor.fit(predictors, target)\n",
    "        folder_path = Path(f\"{models_path}/{model_typology}\")\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        joblib.dump(regressor, folder_path / f\"{name}_{model_typology}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvxm9qE3qJGI"
   },
   "source": [
    "### Model 1: All metrics\n",
    "\n",
    "Model that includes all metrics (likely to overfit and contain redundancy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 884473,
     "status": "ok",
     "timestamp": 1719936430793,
     "user": {
      "displayName": "Marc Maynou Yelamos",
      "userId": "15390060321136749570"
     },
     "user_tz": -120
    },
    "id": "65h-CwQxEtkh",
    "outputId": "5ad7db70-3b28-486e-b966-da5e0ff13482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Fit time: 0.065528 | Score time: 0.003650\n",
      "R2: 0.317465 | MAE: 0.007168 | RMSE: 0.028759 | MedAE: 0.001372\n",
      "------------------------------\n",
      "Ridge Regression\n",
      "Fit time: 0.013035 | Score time: 0.003015\n",
      "R2: 0.317335 | MAE: 0.007165 | RMSE: 0.028762 | MedAE: 0.001371\n",
      "------------------------------\n",
      "Lasso Regression\n",
      "Fit time: 0.020819 | Score time: 0.003402\n",
      "R2: -0.000131 | MAE: 0.008125 | RMSE: 0.034828 | MedAE: 0.004196\n",
      "------------------------------\n",
      "ElasticNet Regression\n",
      "Fit time: 0.021970 | Score time: 0.003218\n",
      "R2: -0.000131 | MAE: 0.008126 | RMSE: 0.034828 | MedAE: 0.004196\n",
      "------------------------------\n",
      "Random Forests\n",
      "Fit time: 32.212540 | Score time: 0.058382\n",
      "R2: 0.836534 | MAE: 0.002037 | RMSE: 0.013992 | MedAE: 0.000003\n",
      "------------------------------\n",
      "Gradient Boosting\n",
      "Fit time: 6.259399 | Score time: 0.007513\n",
      "R2: 0.724397 | MAE: 0.003287 | RMSE: 0.018245 | MedAE: 0.000089\n",
      "------------------------------\n",
      "AdaBoost\n",
      "Fit time: 0.835050 | Score time: 0.010550\n",
      "R2: 0.575613 | MAE: 0.004602 | RMSE: 0.022667 | MedAE: 0.000358\n",
      "------------------------------\n",
      "Extra Trees\n",
      "Fit time: 3.874040 | Score time: 0.074799\n",
      "R2: 0.867274 | MAE: 0.001722 | RMSE: 0.012585 | MedAE: 0.000005\n",
      "------------------------------\n",
      "Histogram Gradient Boosting\n",
      "Fit time: 0.557205 | Score time: 0.015127\n",
      "R2: 0.830613 | MAE: 0.002251 | RMSE: 0.014254 | MedAE: 0.000081\n",
      "------------------------------\n",
      "XGBoosting\n",
      "Fit time: 0.169877 | Score time: 0.014008\n",
      "R2: 0.842361 | MAE: 0.002204 | RMSE: 0.013758 | MedAE: 0.000096\n",
      "------------------------------\n",
      "Light GBM\n",
      "Fit time: 0.096441 | Score time: 0.006852\n",
      "R2: 0.833133 | MAE: 0.002178 | RMSE: 0.014149 | MedAE: 0.000065\n",
      "------------------------------\n",
      "CatBoost\n",
      "Fit time: 5.218588 | Score time: 0.007708\n",
      "R2: 0.863188 | MAE: 0.002115 | RMSE: 0.012772 | MedAE: 0.000283\n",
      "------------------------------\n",
      "MLP Relu\n",
      "Fit time: 1.672375 | Score time: 0.009041\n",
      "R2: -116446.388062 | MAE: 1.258183 | RMSE: 5.867048 | MedAE: 0.197060\n",
      "------------------------------\n",
      "MLP logistic\n",
      "Fit time: 1.411214 | Score time: 0.032205\n",
      "R2: 0.403724 | MAE: 0.011290 | RMSE: 0.026872 | MedAE: 0.006174\n",
      "------------------------------\n",
      "MLP Tanh\n",
      "Fit time: 1.831751 | Score time: 0.014475\n",
      "R2: -0.060369 | MAE: 0.020244 | RMSE: 0.035740 | MedAE: 0.011082\n",
      "------------------------------\n",
      "SVR Poly\n",
      "Fit time: 0.131860 | Score time: 0.031254\n",
      "R2: -7.638337 | MAE: 0.100583 | RMSE: 0.102156 | MedAE: 0.100457\n",
      "------------------------------\n",
      "SVR Rbf\n",
      "Fit time: 0.207829 | Score time: 0.102882\n",
      "R2: -7.472309 | MAE: 0.099566 | RMSE: 0.101174 | MedAE: 0.099622\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_MJ = joined['quality']\n",
    "predictors = joined.drop(columns=['quality'], axis=1)\n",
    "\n",
    "test_list_of_regressors(predictors, y_MJ, names, regressors)\n",
    "\n",
    "# Gradient Boosting -> 0.016195\n",
    "# Extra Trees       -> 0.009650\n",
    "# XGBoosting        -> 0.008856\n",
    "# CatBoost          -> 0.008206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24557,
     "status": "ok",
     "timestamp": 1736505300961,
     "user": {
      "displayName": "Marc Maynou Yelamos",
      "userId": "15390060321136749570"
     },
     "user_tz": -60
    },
    "id": "UoOTDQT3RCD8",
    "outputId": "0c7de7ff-81e0-4ed7-9a5d-7078fdcaed1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:21<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "target = joined['quality']\n",
    "predictors = joined.drop(columns=['quality'], axis=1)\n",
    "\n",
    "store_models(target, predictors, \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2PKzyskqn8O"
   },
   "source": [
    "### Model 2: All metrics + Feature Selection\n",
    "\n",
    "Model 1 + feature selection process to reduce overfitting and redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1736505312623,
     "user": {
      "displayName": "Marc Maynou Yelamos",
      "userId": "15390060321136749570"
     },
     "user_tz": -60
    },
    "id": "sYV37nOWt30H",
    "outputId": "00ad5623-af82-483e-9c2c-bf8b143a942d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for gradient_boosting -> Original = 35, new = 23\n",
      "Number of features for extra_trees -> Original = 35, new = 33\n",
      "Number of features for xgboosting -> Original = 35, new = 31\n",
      "Number of features for catboost -> Original = 35, new = 32\n"
     ]
    }
   ],
   "source": [
    "for name, regressor in zip(best_names, best_regressors):\n",
    "  model_all = joblib.load(f\"{models_path}/all/{name}_all.pkl\")\n",
    "\n",
    "  feature_importances = model_all.feature_importances_\n",
    "  predictors = joined.drop(columns=['quality'], axis=1)\n",
    "\n",
    "  # Match feature importances with corresponding feature names\n",
    "  feature_names = list(predictors.columns)\n",
    "  feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "  # Sort the feature importances in descending order\n",
    "  sorted_feature_importances = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  selected_metrics_fs_all = []\n",
    "  for feature, importance in sorted_feature_importances:\n",
    "    if importance > 0.0001:\n",
    "      selected_metrics_fs_all.append(feature)\n",
    "\n",
    "  target = joined['quality']\n",
    "  predictors = joined[selected_metrics_fs_all]\n",
    "  print(f\"Number of features for {name} -> Original = {len(feature_names)}, new = {len(selected_metrics_fs_all)}\")\n",
    "  # test_list_of_regressors(predictors, target, [name], [regressor])\n",
    "\n",
    "  model = regressor.fit(predictors, target)\n",
    "  folder_path = Path(f\"{models_path}/all_fs\")\n",
    "  folder_path.mkdir(parents=True, exist_ok=True)\n",
    "  joblib.dump(regressor, folder_path / f\"{name}_all_fs.pkl\")\n",
    "\n",
    "\n",
    "# Gradient Boosting -> from 0.016195 to 0.016114, 81 to 39 features\n",
    "# Extra Trees       -> from 0.009650 to 0.009142, 81 to 54 features\n",
    "# XGBoosting        -> from 0.008856 to 0.008714, 81 to 50 features\n",
    "# CatBoost          -> from 0.008206 to 0.007993, 81 to 58 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: In-depth feature selection\n",
    "\n",
    "Multi-layer feature selection. We will only do so for the two best performing models: gradient boosting and extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression, RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def feature_selection_pipeline(dataset, model_typology_name):\n",
    "    y = dataset[\"quality\"]\n",
    "    X = dataset.drop(columns=[\"quality\"], axis=1)\n",
    "    original_features = X.columns.tolist()\n",
    "\n",
    "    print(f\"Original feature count: {len(original_features)}\")\n",
    "\n",
    "    # 1.1 Variance Threshold\n",
    "    var_thresh = VarianceThreshold(threshold = 0.01)\n",
    "    var_thresh.fit(X)\n",
    "    low_variance_removed = X.columns[~var_thresh.get_support()].tolist()\n",
    "    X = X[X.columns[var_thresh.get_support()]]\n",
    "    print(f\"Removed low-variance features: {low_variance_removed}\")\n",
    "    print(f\"Remaining features: {len(X.columns)}\")\n",
    "\n",
    "    # 1.2 Correlation Filter\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_removed = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    X = X.drop(columns=high_corr_removed)\n",
    "    print(f\"Removed highly correlated features: {high_corr_removed}\")\n",
    "    print(f\"Remaining features: {len(X.columns)}\")\n",
    "\n",
    "    # 1.3 Mutual Information\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)\n",
    "    low_mi_removed = mi_scores[mi_scores < 0.01].index.tolist()\n",
    "    X_post_filter_methods = X[mi_scores[mi_scores >= 0.01].index]\n",
    "    print(f\"Removed low mutual information features: {low_mi_removed}\")\n",
    "    print(f\"Remaining features: {len(X_post_filter_methods.columns)}\")\n",
    "\n",
    "    # Utility function for importance + RFECV steps\n",
    "    def run_model_selection(model, model_name):\n",
    "        nonlocal X_post_filter_methods, y\n",
    "\n",
    "        # Feature Importance Filter\n",
    "        model.fit(X_post_filter_methods, y)\n",
    "        feature_importances = model.feature_importances_\n",
    "        feature_names = list(X_post_filter_methods.columns)\n",
    "        feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "        sorted_importances = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        selected_metrics = [f for f, imp in sorted_importances if imp > 0.0001]\n",
    "\n",
    "        X_temp = X_post_filter_methods[selected_metrics]\n",
    "        print(f\"{model_name} - Selected {len(X_temp.columns)} features after importance filtering\")\n",
    "\n",
    "        # RFECV\n",
    "        rfecv = RFECV(estimator=model, step=1, cv=KFold(5), scoring='r2',verbose=3)\n",
    "        rfecv.fit(X_temp, y)\n",
    "        selected = X_temp.columns[rfecv.support_]\n",
    "        print(f\"{model_name} - Optimal number of features: {rfecv.n_features_}\")\n",
    "        print(f\"{model_name} - Selected features: {list(selected)}\")\n",
    "\n",
    "        # Train final model\n",
    "        model.fit(X_temp[selected], y)\n",
    "        folder_path = Path(models_path) / model_typology_name\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        model_file = folder_path / f\"{model_name}_{model_typology_name}.pkl\"\n",
    "        joblib.dump(model, model_file)\n",
    "        print(f\"Saved model to: {model_file}\")\n",
    "\n",
    "        return list(selected)\n",
    "\n",
    "    run_model_selection(GradientBoostingRegressor(random_state=21111999, n_estimators=50), \"gradient_boosting\")\n",
    "    run_model_selection(ExtraTreesRegressor(random_state=21111999, n_estimators=50), \"extra_trees\")\n",
    "    run_model_selection(XGBRegressor(random_state=211199, n_estimators=50), \"xgboosting\")\n",
    "    run_model_selection(CatBoostRegressor(random_state=211199, verbose=0), \"catboost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature count: 35\n",
      "Removed low-variance features: ['is_empty']\n",
      "Remaining features: 34\n",
      "Removed highly correlated features: ['constancy', 'frequency_1qo', 'frequency_2qo', 'frequency_3qo', 'frequency_4qo', 'frequency_6qo', 'frequency_7qo', 'words_cnt_sd']\n",
      "Remaining features: 26\n",
      "Removed low mutual information features: []\n",
      "Remaining features: 26\n",
      "gradient_boosting - Selected 17 features after importance filtering\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "gradient_boosting - Optimal number of features: 10\n",
      "gradient_boosting - Selected features: ['freq_word_containment', 'frequency_avg', 'frequency_max', 'number_words', 'frequency_min', 'first_word', 'val_pct_min', 'name_dist', 'last_word', 'frequency_sd']\n",
      "Saved model to: C:\\Projects\\freyja_plus_more\\models_postnormalized_all\\all_fs_deep\\gradient_boosting_all_fs_deep.pkl\n",
      "extra_trees - Selected 25 features after importance filtering\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "extra_trees - Optimal number of features: 21\n",
      "extra_trees - Selected features: ['freq_word_containment', 'name_dist', 'freq_word_soundex_containment', 'uniqueness', 'first_word', 'number_words', 'val_pct_max', 'frequency_5qo', 'val_pct_std', 'frequency_avg', 'val_pct_min', 'frequency_max', 'frequency_iqr', 'last_word', 'len_max_word', 'entropy', 'frequency_min', 'frequency_sd', 'incompleteness', 'len_avg_word', 'cardinality']\n",
      "Saved model to: C:\\Projects\\freyja_plus_more\\models_postnormalized_all\\all_fs_deep\\extra_trees_all_fs_deep.pkl\n",
      "xgboosting - Selected 24 features after importance filtering\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "xgboosting - Optimal number of features: 16\n",
      "xgboosting - Selected features: ['frequency_min', 'frequency_max', 'freq_word_containment', 'frequency_avg', 'len_max_word', 'frequency_sd', 'first_word', 'last_word', 'number_words', 'entropy', 'frequency_iqr', 'name_dist', 'val_pct_min', 'frequency_5qo', 'freq_word_soundex_containment', 'len_avg_word']\n",
      "Saved model to: C:\\Projects\\freyja_plus_more\\models_postnormalized_all\\all_fs_deep\\xgboosting_all_fs_deep.pkl\n",
      "catboost - Selected 24 features after importance filtering\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "catboost - Optimal number of features: 15\n",
      "catboost - Selected features: ['frequency_avg', 'freq_word_containment', 'frequency_max', 'number_words', 'first_word', 'last_word', 'len_max_word', 'name_dist', 'frequency_5qo', 'val_pct_min', 'freq_word_soundex_containment', 'len_avg_word', 'frequency_min', 'entropy', 'cardinality']\n",
      "Saved model to: C:\\Projects\\freyja_plus_more\\models_postnormalized_all\\all_fs_deep\\catboost_all_fs_deep.pkl\n"
     ]
    }
   ],
   "source": [
    "# no_syntactic_features = merged_no_dummies[['quality', 'name_dist', 'frequency_max', 'uniqueness', 'first_word', 'frequency_4qo', 'freq_word_containment', 'len_avg_word', 'words_cnt_max',\n",
    "#                                 'frequency_6qo', 'len_max_word', 'frequency_min', 'frequency_3qo', 'is_empty', 'frequency_iqr', 'entropy', 'val_pct_std',\n",
    "#                                 'words_cnt_min', 'cardinality', 'words_cnt_sd', 'val_pct_max', 'len_min_word', 'words_cnt_avg']]\n",
    "\n",
    "feature_selection_pipeline(joined, \"all_fs_deep\")\n",
    "# feature_selection_pipeline(no_syntactic_features, \"no_syntactic_fs_deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics_fs_no_syntactic = ['name_dist', 'frequency_max', 'uniqueness', 'first_word', 'frequency_4qo', 'freq_word_containment', 'len_avg_word', 'words_cnt_max',\n",
    "                                      'frequency_6qo', 'len_max_word', 'frequency_min', 'frequency_3qo', 'is_empty', 'frequency_iqr', 'entropy', 'val_pct_std',\n",
    "                                      'words_cnt_min', 'cardinality', 'words_cnt_sd', 'val_pct_max', 'len_min_word', 'words_cnt_avg']\n",
    "\n",
    "for name, regressor in zip(best_names, best_regressors):\n",
    "  target = joined['quality']\n",
    "  predictors = joined[selected_metrics_fs_no_syntactic]\n",
    "\n",
    "\n",
    "  model = regressor.fit(predictors, target)\n",
    "  folder_path = Path(f\"{models_path}/custom\")\n",
    "  folder_path.mkdir(parents=True, exist_ok=True)\n",
    "  joblib.dump(regressor, folder_path / f\"{name}_custom.pkl\")\n",
    "\n",
    "\n",
    "# Gradient Boosting -> models 1-2 -> from 0.016195 to 0.016114, 81 to 39 features\n",
    "#                   -> models 3-4 -> from 0.016299 to 0.016298, 36 to 30 features\n",
    "# Extra Trees       -> models 1-2 -> from 0.009650 to 0.009142, 81 to 54 features\n",
    "#                   -> models 3-4 -> from 0.008569 to 0.008568, 36 to 33 features\n",
    "# XGBoosting        -> models 1-2 -> from 0.008856 to 0.008714, 81 to 50 features\n",
    "#                   -> models 3-4 -> from 0.008252 to 0.008197, 36 to 32 features\n",
    "# CatBoost          -> models 1-2 -> from 0.008206 to 0.007993, 81 to 58 features\n",
    "#                   -> models 3-4 -> from 0.008011 to 0.008055, 36 to 33 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# -----------------------------\n",
    "# Paths and data\n",
    "# -----------------------------\n",
    "models_path = \"C:/Projects/freyja_plus_more/models_prenormalized_base/\"\n",
    "folder_path = Path(models_path) / \"custom_more\"\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "selected_metrics_fs_no_syntactic = [\n",
    "    'name_dist', 'frequency_max', 'uniqueness', 'first_word',\n",
    "    'frequency_4qo', 'freq_word_containment', 'len_avg_word',\n",
    "    'words_cnt_max', 'frequency_6qo', 'len_max_word',\n",
    "    'frequency_min', 'frequency_3qo', 'is_empty',\n",
    "    'frequency_iqr', 'entropy', 'val_pct_std',\n",
    "    'words_cnt_min', 'cardinality', 'words_cnt_sd',\n",
    "    'val_pct_max', 'len_min_word', 'words_cnt_avg'\n",
    "]\n",
    "\n",
    "predictors = joined[selected_metrics_fs_no_syntactic]\n",
    "target = joined['quality']\n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameter grid\n",
    "# -----------------------------\n",
    "param_grid = {\n",
    "    \"n_estimators\": [25, 50, 100],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"min_samples_leaf\": [1, 10]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Training loop\n",
    "# -----------------------------\n",
    "for values in product(*param_grid.values()):\n",
    "    params = dict(zip(param_grid.keys(), values))\n",
    "\n",
    "    regressor = GradientBoostingRegressor(\n",
    "        random_state=211199,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    regressor.fit(predictors, target)\n",
    "\n",
    "    # Descriptive model filename\n",
    "    model_name = (\n",
    "        f\"gradient_boosting_prenormalized_base_\"\n",
    "        f\"ne{params['n_estimators']}_\"\n",
    "        f\"lr{params['learning_rate']}_\"\n",
    "        f\"md{params['max_depth']}_\"\n",
    "        f\"ss{params['subsample']}_\"\n",
    "        f\"msl{params['min_samples_leaf']}.pkl\"\n",
    "    )\n",
    "\n",
    "    joblib.dump(regressor, folder_path / model_name)\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: save the hyperparameter grid for reference\n",
    "# -----------------------------\n",
    "import json\n",
    "with open(folder_path / \"model_configs.json\", \"w\") as f:\n",
    "    json.dump(param_grid, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQHVWZM7qcZo"
   },
   "source": [
    "# Benchmark evaluation\n",
    "\n",
    "Once we have define all the models, we will evaluate each of the seven selected benchmarks with all of them, with the goal of discerning which is the best one. To do so, all the distances for all query columns of each benchmark have been obtained and stored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb-lbfUVSJHZ"
   },
   "source": [
    "## Preparation\n",
    "Load all the model and define the functions to prepare the data for the models. This data preparation depends on the features defined for each model. We also present the function used to obtain the metrics from the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10'])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "models = {}\n",
    "typologies = [\"custom_more\"]\n",
    "\n",
    "models_path = 'C:/Projects/freyja_plus_more/models_prenormalized_base/custom_more'\n",
    "\n",
    "for filename in os.listdir(models_path):\n",
    "    if filename.endswith(\"gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10.pkl\"):  # Only load joblib files\n",
    "        model_name = os.path.splitext(filename)[0]\n",
    "        file_path = os.path.join(models_path, filename)\n",
    "        models[model_name] = joblib.load(file_path)\n",
    "\n",
    "print(models.keys())\n",
    "print(len(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "error",
     "timestamp": 1736438929909,
     "user": {
      "displayName": "Marc Maynou Yelamos",
      "userId": "15390060321136749570"
     },
     "user_tz": -60
    },
    "id": "VDQPdy3WHVQ3",
    "outputId": "969caa2f-defd-4878-d983-8a9dc4bb706d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gradient_boosting_all', 'gradient_boosting_all_fs', 'gradient_boosting_all_fs_deep', 'gradient_boosting_custom', 'extra_trees_all', 'extra_trees_all_fs', 'extra_trees_all_fs_deep', 'extra_trees_custom'])\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "best_names = [\n",
    "        \"gradient_boosting\",\n",
    "        \"extra_trees\",\n",
    "        # \"xgboosting\",\n",
    "        # \"catboost\"\n",
    "    ]\n",
    "\n",
    "models = {}\n",
    "# typologies = [\"all\", \"all_fs\", \"no_syntactic\", \"no_syntactic_fs\", \"all_fs_deep\", \"no_syntactic_fs_deep\"]\n",
    "typologies = [\"all\", \"all_fs\", \"all_fs_deep\", \"custom\"]\n",
    "# typologies = [\"all_fs_deep\", \"custom\"]\n",
    "# typologies = [\"custom_more\"]\n",
    "\n",
    "models_path = 'C:/Projects/freyja_plus_more/models_postnormalized_all/'\n",
    "\n",
    "for name in best_names:\n",
    "    for type in typologies:\n",
    "        try:\n",
    "            models[f\"{name}_{type}\"] = joblib.load(f'{models_path}/{type}/{name}_{type}.pkl')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "print(models.keys())\n",
    "print(len(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "id": "J9kqsOF3FVUk"
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_model(distances, model, type_of_model):\n",
    "  distances = distances.drop(columns=['dataset_name', 'dataset_name_2', 'attribute_name', 'attribute_name_2'], axis=1)\n",
    "\n",
    "  maybe_missing_columns = [\"datatype__pct_alphabetic\", \"datatype__pct_date_time\", \"datatype__pct_non_alphanumeric\", \"datatype__pct_numeric\", \"datatype__pct_unknown\", \"datatype__pct_alphanumeric\",\n",
    "                            \"specific_type__pct_date\", \"specific_type__pct_email\", \"specific_type__pct_phrases\", 'specific_type_2__pct_username', 'datatype_2__pct_alphanumeric', 'datatype_2__pct_alphabetic',\n",
    "                            'specific_type_2__pct_phrases', \"specific_type__pct_general\", \"specific_type__pct_others\", \"specific_type__pct_time\", \"specific_type__pct_url\", \"specific_type__pct_username\",\n",
    "                            'datatype_2__pct_date_time', 'specific_type_2__pct_date', 'specific_type_2__pct_email', 'specific_type_2__pct_general', 'specific_type_2__pct_url', 'datatype_2__pct_non_alphanumeric',\n",
    "                            'datatype_2__pct_numeric', 'datatype_2__pct_unknown', 'specific_type_2__pct_others', 'specific_type_2__pct_time']\n",
    "\n",
    "  # if \"no_syntactic_fs\" in type_of_model or \"custom\" in type_of_model:\n",
    "  #   pass\n",
    "  # elif (\"all\" in type_of_model):\n",
    "  #   distances = pd.concat([distances.drop('datatype', axis=1), pd.get_dummies(distances['datatype'], prefix='datatype_', dtype=int)], axis=1)\n",
    "  #   distances = pd.concat([distances.drop('datatype_2', axis=1), pd.get_dummies(distances['datatype_2'], prefix='datatype_2_', dtype=int)], axis=1)\n",
    "  #   distances = pd.concat([distances.drop('specific_type', axis=1), pd.get_dummies(distances['specific_type'], prefix='specific_type_', dtype=int)], axis=1)\n",
    "  #   distances = pd.concat([distances.drop('specific_type_2', axis=1), pd.get_dummies(distances['specific_type_2'], prefix='specific_type_2_', dtype=int)], axis=1)\n",
    "\n",
    "  #   for column in maybe_missing_columns:\n",
    "  #     if column not in distances.columns:\n",
    "  #       distances[column] = 0\n",
    "  # else:\n",
    "  #   distances = distances.drop(columns=['datatype', \"datatype_2\", \"specific_type\", \"specific_type_2\"], axis=1, errors='ignore')\n",
    "  #   distances = distances.drop(columns=[\"pct_numeric\", \"pct_alphanumeric\", \"pct_alphabetic\", \"pct_non_alphanumeric\", \"pct_date_time\", \"pct_unknown\", \"pct_phones\", \"pct_email\", \"pct_url\", \"pct_ip\",\n",
    "  #                                       \"pct_username\", \"pct_phrases\", \"pct_general\", \"pct_date\", \"pct_time\", \"pct_date_time_specific\", \"pct_others\"], axis=1, errors='ignore')\n",
    "\n",
    "  if 'is_empty_2' not in distances.columns:\n",
    "    distances['is_empty_2'] = 0\n",
    "\n",
    "  # Arrange the columns as in the model\n",
    "  if \"catboost\" in type_of_model:\n",
    "    distances = distances[model.feature_names_] \n",
    "  else:\n",
    "    distances = distances[model.feature_names_in_] \n",
    "  return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "id": "OTTtg8E9Q0-T"
   },
   "outputs": [],
   "source": [
    "def compute_and_evaluate_ranking(model, model_type, k, step, ground_truth_path, distances_folder_path):\n",
    "  # Read the ground truth and obtain, for every target column, the amount of candidate columns that it has a join with. This will allow us to calculate the recall,\n",
    "  # as it indicates the maximum possible joins, regardless of the value of k\n",
    "  ground_truth = pd.read_csv(ground_truth_path, header = 0)\n",
    "  pair_counts = ground_truth.groupby(['target_ds', 'target_attr']).size().reset_index(name='joins_count')\n",
    "\n",
    "  # Initialize the matrix of metrics\n",
    "  num_observations = int(k / step)\n",
    "  precision = [0] * num_observations\n",
    "  recall = [0] * num_observations\n",
    "  max_recall = [0] * num_observations\n",
    "  MAP = [0] * num_observations\n",
    "\n",
    "  # Initialize execution time\n",
    "  total_time = 0\n",
    "\n",
    "  for _, row in tqdm(pair_counts.iterrows(), total=len(pair_counts)):\n",
    "      dataset = row['target_ds']\n",
    "      attribute = row['target_attr']\n",
    "      count = row['joins_count']\n",
    "\n",
    "      st = time.time()\n",
    "\n",
    "      # Read the distances and do some preprocessing\n",
    "      distances = pd.read_csv(distances_folder_path + 'distances_' + dataset.replace(\".csv\", \"_profile_\") + attribute.replace(\"/\", \"_\").replace(\": \",\"_\") + \".csv\", header = 0, encoding='latin1', on_bad_lines=\"skip\")\n",
    "\n",
    "      dataset_names = distances[\"dataset_name_2\"] # We store dataset and attribute names to be used to evaluate the ranking\n",
    "      attribute_names = distances[\"attribute_name_2\"]\n",
    "      distances = prepare_data_for_model(distances, model, model_type)\n",
    "\n",
    "      # # Use the model to predict\n",
    "      # y_pred = model.predict(distances)\n",
    "      # distances[\"predictions\"] = y_pred\n",
    "\n",
    "      # Use the model to predict (preventing some weird lines that might have slipped in)\n",
    "      distances_numeric = distances.apply(pd.to_numeric, errors='coerce') # Convert everything to float, invalid parsing becomes NaN\n",
    "      valid_rows = distances_numeric.dropna(axis=0, how='any') # Keep track of valid rows\n",
    "      y_pred = model.predict(valid_rows) # Predict only on valid rows\n",
    "      distances.loc[valid_rows.index, \"predictions\"] = y_pred # Assign predictions back only to the valid rows\n",
    "\n",
    "      distances[\"target_ds\"] = dataset_names\n",
    "      distances[\"target_attr\"] = attribute_names\n",
    "\n",
    "      total_time += (time.time() - st) # In the time assessment we do not consider the evaluation of the ranking\n",
    "\n",
    "      # Precompute a lookup set of valid (candidate_ds, candidate_attr) for this query\n",
    "      valid_pairs = set(\n",
    "          ground_truth.loc[\n",
    "              (ground_truth['target_ds'] == dataset) &\n",
    "              (ground_truth['target_attr'] == attribute),\n",
    "              ['candidate_ds', 'candidate_attr']\n",
    "          ].itertuples(index=False, name=None)\n",
    "      )\n",
    "\n",
    "      # For every k that we want to assess the ranking of, we get the top k joins and check how many appear in the grpund truth\n",
    "      for k_iter in range(1, num_observations + 1):\n",
    "        count_sem = 0\n",
    "        ap = 0\n",
    "        count_positions = 0\n",
    "\n",
    "        top_k_joins = distances.sort_values(by='predictions', ascending=False).head(k_iter * step)\n",
    "\n",
    "        for position in top_k_joins.itertuples(index=False):\n",
    "            pair = (position.target_ds, position.target_attr)\n",
    "            if pair in valid_pairs: \n",
    "                count_sem += 1\n",
    "                ap += count_sem / (count_positions + 1)\n",
    "            count_positions += 1\n",
    "\n",
    "\n",
    "        precision[k_iter - 1] += count_sem / (k_iter * step)\n",
    "        if count_sem != 0:\n",
    "            MAP[k_iter - 1] += ap / count_sem\n",
    "        recall[k_iter - 1] += count_sem / count\n",
    "        max_recall[k_iter - 1] += (k_iter * step) / count\n",
    "\n",
    "  print(\"AVERAGE time to load the distances and execute the model:\")\n",
    "  print(\"----%.2f----\" % (total_time / len(pair_counts)))\n",
    "\n",
    "  print(\"Precisions:\", [round(element / len(pair_counts), 4) for element in precision])\n",
    "#   print(\"Recall:\", [round(element / len(pair_counts), 4) for element in recall])\n",
    "#   print(\"Max recall:\", [round(element / len(pair_counts), 4) for element in max_recall])\n",
    "#   print(\"Recall percentage:\", [round((recall_iter / len(pair_counts)) / (max_recall_iter / len(pair_counts)), 4) for recall_iter, max_recall_iter in zip(recall, max_recall)])\n",
    "#   print(\"MAP:\", [round(element / len(pair_counts), 4) for element in MAP])\n",
    "\n",
    "  return [round(element / len(pair_counts), 4) for element in precision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYVafCqwHcFK"
   },
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(k, step, ground_truth_path, distances_folder_path, models=models):\n",
    "    results = {}\n",
    "\n",
    "    for model_type, model in models.items():\n",
    "        print(f\"Model {model_type}\")\n",
    "        precision_scores = compute_and_evaluate_ranking(\n",
    "            model, model_type, k, step, ground_truth_path, distances_folder_path\n",
    "        )\n",
    "        results[model_type] = precision_scores\n",
    "        print(\"------------------------------------------------------\")\n",
    "\n",
    "    # Compute average precisions\n",
    "    avg_precisions = {\n",
    "        model_name: sum(precisions) / len(precisions)\n",
    "        for model_name, precisions in results.items()\n",
    "    }\n",
    "\n",
    "    # Sort models from best to worst\n",
    "    ranked_models = sorted(avg_precisions.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print ranked results\n",
    "    print(\"\\n==================== MODEL RANKINGS ====================\")\n",
    "    for rank, (model_name, avg_precision) in enumerate(ranked_models, start=1):\n",
    "        print(f\"{rank:2d}. Model: {model_name:20s} | Avg Precision: {avg_precision:.4f}\")\n",
    "\n",
    "    print(\"========================================================\")\n",
    "\n",
    "    # return ranked_models, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oibWXdIE4oN"
   },
   "source": [
    "### Santos Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.05----\n",
      "Precisions: [1.0, 0.97, 0.96, 0.955, 0.94, 0.9333, 0.9286, 0.925, 0.9222, 0.914]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9448\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "step = 1\n",
    "ground_truth_path = 'C:/Projects/benchmarks/santos_small/santos_small_ground_truth.csv'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/santos_small/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [1.0, 0.97, 0.96, 0.955, 0.94, 0.9333, 0.9286, 0.925, 0.9222, 0.914]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9448\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "step = 1\n",
    "ground_truth_path = 'C:/Projects/benchmarks/santos_small/santos_small_ground_truth.csv'\n",
    "distances_folder_path = 'C:/Projects/test/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "step = 1\n",
    "ground_truth_path = 'C:/Projects/benchmarks/santos_small/santos_small_ground_truth.csv'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/santos_small/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.15----\n",
      "Precisions: [0.975, 0.901, 0.835, 0.865, 0.887, 0.901]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.97, 0.903, 0.8353, 0.8662, 0.8874, 0.9022]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.969, 0.9155, 0.8597, 0.8712, 0.8864, 0.9008]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.972, 0.915, 0.8603, 0.8842, 0.903, 0.9143]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.967, 0.9275, 0.888, 0.9055, 0.9084, 0.8907]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.969, 0.911, 0.853, 0.874, 0.8896, 0.8727]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.966, 0.888, 0.8327, 0.8432, 0.8608, 0.865]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.13----\n",
      "Precisions: [0.972, 0.8625, 0.738, 0.6863, 0.6628, 0.6375]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.97, 0.9225, 0.8657, 0.8747, 0.866, 0.8678]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.969, 0.9145, 0.848, 0.8365, 0.8234, 0.8038]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.968, 0.9185, 0.8677, 0.861, 0.8574, 0.8253]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.969, 0.9065, 0.8347, 0.835, 0.819, 0.7895]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.13----\n",
      "Precisions: [0.971, 0.87, 0.7793, 0.7895, 0.7596, 0.7298]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.974, 0.9035, 0.839, 0.843, 0.8302, 0.7977]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.971, 0.855, 0.7177, 0.6493, 0.5832, 0.5265]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.973, 0.8685, 0.762, 0.7085, 0.6718, 0.623]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.974, 0.902, 0.8357, 0.8517, 0.8702, 0.8813]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.975, 0.902, 0.836, 0.8517, 0.8692, 0.879]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.975, 0.902, 0.835, 0.8517, 0.869, 0.8805]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.976, 0.902, 0.8363, 0.8515, 0.8688, 0.8803]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.974, 0.905, 0.8407, 0.8685, 0.8866, 0.8907]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.964, 0.9065, 0.8453, 0.872, 0.8896, 0.9002]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.974, 0.906, 0.8473, 0.8722, 0.8896, 0.901]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.971, 0.9025, 0.8377, 0.8632, 0.8834, 0.8937]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.977, 0.9025, 0.837, 0.8537, 0.875, 0.891]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.969, 0.902, 0.8387, 0.8685, 0.889, 0.9033]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.976, 0.902, 0.838, 0.8537, 0.8738, 0.8903]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.976, 0.902, 0.8387, 0.8675, 0.8886, 0.9032]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.968, 0.9065, 0.8477, 0.8757, 0.8952, 0.9067]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.968, 0.919, 0.869, 0.8937, 0.9072, 0.9105]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.974, 0.906, 0.848, 0.877, 0.8962, 0.9087]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.97, 0.9035, 0.8387, 0.8672, 0.8884, 0.8943]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.966, 0.902, 0.8363, 0.8537, 0.8748, 0.8912]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.974, 0.9025, 0.8377, 0.8547, 0.8758, 0.8908]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.978, 0.9025, 0.8357, 0.8532, 0.8742, 0.8905]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.976, 0.902, 0.8393, 0.8677, 0.8888, 0.9022]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.972, 0.918, 0.8657, 0.8905, 0.907, 0.9167]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.971, 0.919, 0.8737, 0.8935, 0.909, 0.9182]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.967, 0.914, 0.861, 0.8857, 0.9028, 0.9127]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.971, 0.9025, 0.839, 0.8685, 0.8882, 0.8945]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.13----\n",
      "Precisions: [0.966, 0.9275, 0.8833, 0.9012, 0.9156, 0.9247]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.12----\n",
      "Precisions: [0.971, 0.9155, 0.8577, 0.884, 0.9016, 0.9138]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.975, 0.915, 0.8613, 0.8842, 0.901, 0.9143]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.97, 0.9145, 0.8617, 0.8837, 0.9016, 0.9133]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.976, 0.918, 0.872, 0.887, 0.8852, 0.8757]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.10----\n",
      "Precisions: [0.968, 0.9035, 0.8547, 0.8755, 0.8756, 0.8568]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.973, 0.9315, 0.895, 0.9117, 0.9222, 0.9112]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.11----\n",
      "Precisions: [0.976, 0.893, 0.8347, 0.843, 0.8288, 0.8163]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.9241\n",
      " 2. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.9197\n",
      " 3. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9145\n",
      " 4. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.9141\n",
      " 5. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9116\n",
      " 6. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.9112\n",
      " 7. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.9085\n",
      " 8. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.9081\n",
      " 9. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9075\n",
      "10. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.9073\n",
      "11. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.9072\n",
      "12. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.9023\n",
      "13. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.9016\n",
      "14. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.9004\n",
      "15. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.9000\n",
      "16. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.8983\n",
      "17. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.8963\n",
      "18. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.8960\n",
      "19. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.8960\n",
      "20. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.8951\n",
      "21. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.8949\n",
      "22. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.8944\n",
      "23. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.8942\n",
      "24. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.8940\n",
      "25. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.8940\n",
      "26. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.8939\n",
      "27. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.8937\n",
      "28. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.8919\n",
      "29. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.8894\n",
      "30. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.8892\n",
      "31. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.8890\n",
      "32. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.8890\n",
      "33. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.8890\n",
      "34. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.8873\n",
      "35. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.8858\n",
      "36. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.8858\n",
      "37. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.8855\n",
      "38. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.8855\n",
      "39. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.8830\n",
      "40. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.8760\n",
      "41. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.8659\n",
      "42. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.8653\n",
      "43. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.8646\n",
      "44. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.8590\n",
      "45. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.8165\n",
      "46. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.7678\n",
      "47. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.7599\n",
      "48. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.7171\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 60\n",
    "step = 10\n",
    "ground_truth_path = 'C:/Projects/benchmarks/tus_small/tus_small_ground_truth.csv'\n",
    "# distances_folder_path = 'C:/Projects/freyja_plus_more/distances/tus_small/'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/tus_small/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)\n",
    "\n",
    "#Original ->  2. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.8939\n",
    "#Supernormalize ->  1. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.8974\n",
    "\n",
    "# Prenormalized_all:  1. Model: gradient_boosting_custom | Avg Precision: 0.9075\n",
    "                    # 2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.8966\n",
    "\n",
    "# Prenormalized_base:  1. Model: gradient_boosting_custom | Avg Precision: 0.9085\n",
    "                    #  2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.8975\n",
    "\n",
    "# Base                   . Model: gradient_boosting_custom | Avg Precision: 0.8942\n",
    "                    #   2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.8841\n",
    "\n",
    "# postnormalized_base:  1. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.8837\n",
    "                    #   2. Model: gradient_boosting_custom | Avg Precision: 0.8780\n",
    "\n",
    "# postnormalized_all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.42----\n",
      "Precisions: [0.96, 0.958, 0.9417, 0.9205, 0.9, 0.8928]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.39----\n",
      "Precisions: [0.958, 0.9575, 0.946, 0.929, 0.9098, 0.8962]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.38----\n",
      "Precisions: [0.968, 0.961, 0.9457, 0.93, 0.9094, 0.8998]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.36----\n",
      "Precisions: [0.971, 0.9675, 0.9597, 0.944, 0.9208, 0.907]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.41----\n",
      "Precisions: [0.979, 0.963, 0.9407, 0.9103, 0.8868, 0.8687]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.961, 0.945, 0.9187, 0.894, 0.8734, 0.8582]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.42----\n",
      "Precisions: [0.967, 0.943, 0.9093, 0.8908, 0.8644, 0.847]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.963, 0.9225, 0.8713, 0.8378, 0.8034, 0.7708]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.39----\n",
      "Precisions: [0.933, 0.9035, 0.8687, 0.8505, 0.8314, 0.8052]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.51----\n",
      "Precisions: [0.956, 0.95, 0.9407, 0.9252, 0.9042, 0.8877]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:03<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.53----\n",
      "Precisions: [0.951, 0.927, 0.885, 0.8473, 0.8142, 0.7915]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.51----\n",
      "Precisions: [0.969, 0.9505, 0.933, 0.9068, 0.8754, 0.8512]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:03<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.54----\n",
      "Precisions: [0.961, 0.93, 0.8937, 0.8705, 0.8416, 0.8142]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:55<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.46----\n",
      "Precisions: [0.947, 0.9215, 0.8967, 0.875, 0.8492, 0.8282]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:46<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.38----\n",
      "Precisions: [0.958, 0.9245, 0.8643, 0.8148, 0.7706, 0.7272]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.38----\n",
      "Precisions: [0.955, 0.9195, 0.8903, 0.8618, 0.8334, 0.8047]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.964, 0.9535, 0.9403, 0.922, 0.8982, 0.8832]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.34----\n",
      "Precisions: [0.961, 0.9525, 0.9403, 0.9225, 0.8986, 0.8833]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.959, 0.9475, 0.9257, 0.9023, 0.8852, 0.87]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.961, 0.9485, 0.9327, 0.9155, 0.896, 0.8828]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.34----\n",
      "Precisions: [0.959, 0.951, 0.923, 0.8902, 0.858, 0.8362]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.962, 0.9475, 0.924, 0.894, 0.867, 0.8478]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.957, 0.946, 0.9197, 0.8925, 0.866, 0.8435]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.965, 0.9545, 0.9327, 0.9045, 0.8782, 0.8622]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.965, 0.952, 0.9463, 0.93, 0.9148, 0.9032]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.965, 0.9535, 0.9433, 0.9272, 0.9126, 0.903]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.34----\n",
      "Precisions: [0.961, 0.955, 0.9433, 0.9227, 0.9046, 0.8933]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.34----\n",
      "Precisions: [0.965, 0.958, 0.949, 0.9295, 0.9092, 0.8943]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.969, 0.9575, 0.9443, 0.9287, 0.9088, 0.8907]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.964, 0.9455, 0.9257, 0.8982, 0.8766, 0.8602]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.969, 0.9525, 0.9317, 0.9112, 0.8884, 0.873]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.964, 0.95, 0.9307, 0.9137, 0.8934, 0.8782]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:09<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----1.23----\n",
      "Precisions: [0.963, 0.955, 0.944, 0.927, 0.9066, 0.8957]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.966, 0.958, 0.9443, 0.924, 0.9038, 0.8957]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.963, 0.9545, 0.9413, 0.9202, 0.9014, 0.8925]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.966, 0.9585, 0.945, 0.9265, 0.9082, 0.8987]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.966, 0.961, 0.941, 0.916, 0.895, 0.8792]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.958, 0.9535, 0.9337, 0.909, 0.8864, 0.8723]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.36----\n",
      "Precisions: [0.972, 0.9545, 0.9377, 0.9128, 0.8886, 0.8717]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.36----\n",
      "Precisions: [0.962, 0.9455, 0.9293, 0.9102, 0.8912, 0.8745]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.965, 0.9535, 0.9413, 0.9245, 0.911, 0.908]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.959, 0.9455, 0.9373, 0.9222, 0.9018, 0.892]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.969, 0.9585, 0.946, 0.9317, 0.9116, 0.9032]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.35----\n",
      "Precisions: [0.969, 0.961, 0.9527, 0.9345, 0.915, 0.9007]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.36----\n",
      "Precisions: [0.969, 0.956, 0.925, 0.9008, 0.8792, 0.8655]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.36----\n",
      "Precisions: [0.953, 0.9275, 0.8877, 0.8605, 0.8336, 0.8122]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.36----\n",
      "Precisions: [0.976, 0.9645, 0.937, 0.9125, 0.892, 0.8773]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.36----\n",
      "Precisions: [0.962, 0.9335, 0.8983, 0.876, 0.8482, 0.8282]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.9450\n",
      " 2. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9388\n",
      " 3. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.9367\n",
      " 4. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.9356\n",
      " 5. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.9352\n",
      " 6. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9342\n",
      " 7. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.9341\n",
      " 8. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.9339\n",
      " 9. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.9338\n",
      "10. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.9332\n",
      "11. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.9327\n",
      "12. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.9320\n",
      "13. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.9319\n",
      "14. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.9300\n",
      "15. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.9288\n",
      "16. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.9288\n",
      "17. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.9273\n",
      "18. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.9269\n",
      "19. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.9266\n",
      "20. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.9264\n",
      "21. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9264\n",
      "22. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.9263\n",
      "23. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9248\n",
      "24. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.9229\n",
      "25. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.9228\n",
      "26. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.9217\n",
      "27. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.9210\n",
      "28. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.9188\n",
      "29. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.9188\n",
      "30. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.9162\n",
      "31. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.9159\n",
      "32. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.9150\n",
      "33. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9143\n",
      "34. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.9117\n",
      "35. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.9084\n",
      "36. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.9071\n",
      "37. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.9041\n",
      "38. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.9036\n",
      "39. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9029\n",
      "40. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.8910\n",
      "41. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.8863\n",
      "42. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.8852\n",
      "43. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.8791\n",
      "44. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.8774\n",
      "45. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.8693\n",
      "46. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.8654\n",
      "47. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.8615\n",
      "48. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.8432\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 60\n",
    "step = 10\n",
    "ground_truth_path = 'C:/Projects/benchmarks/tus_big/tus_big_ground_truth_sample.csv'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/tus_big/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)\n",
    "\n",
    "#Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.9718\n",
    "#Supernormalized ->  1. Model: gradient_boosting_custom | Avg Precision: 0.9411\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.08----\n",
      "Precisions: [0.817, 0.8105, 0.817, 0.8033, 0.787, 0.7872, 0.783, 0.7707, 0.7519, 0.7328]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.811, 0.8075, 0.796, 0.7788, 0.7634, 0.7728, 0.7814, 0.772, 0.7547, 0.7398]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.822, 0.8205, 0.8107, 0.7873, 0.7648, 0.7687, 0.7733, 0.7634, 0.7482, 0.7364]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.825, 0.8165, 0.803, 0.7848, 0.762, 0.7665, 0.7743, 0.7669, 0.7512, 0.7387]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.808, 0.822, 0.8077, 0.765, 0.7458, 0.7492, 0.7417, 0.7291, 0.715, 0.6969]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.754, 0.762, 0.7633, 0.738, 0.7242, 0.7293, 0.7216, 0.7097, 0.6944, 0.6777]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.776, 0.782, 0.78, 0.7603, 0.7532, 0.7458, 0.7313, 0.7149, 0.6941, 0.6759]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.593, 0.5705, 0.5583, 0.5705, 0.564, 0.5603, 0.5634, 0.5711, 0.5739, 0.5732]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.608, 0.6705, 0.6817, 0.7042, 0.7198, 0.7308, 0.7413, 0.7365, 0.7228, 0.708]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.803, 0.789, 0.7957, 0.771, 0.74, 0.7435, 0.7421, 0.7356, 0.7231, 0.709]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.735, 0.7175, 0.7333, 0.722, 0.703, 0.7072, 0.7056, 0.6977, 0.6891, 0.6826]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.783, 0.7685, 0.7467, 0.7153, 0.6864, 0.6928, 0.6951, 0.6907, 0.6807, 0.6714]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.753, 0.724, 0.686, 0.6305, 0.615, 0.6058, 0.5927, 0.5766, 0.558, 0.5385]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.781, 0.762, 0.743, 0.718, 0.6946, 0.6727, 0.6536, 0.6357, 0.6202, 0.6004]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.692, 0.676, 0.6523, 0.6268, 0.6144, 0.593, 0.5797, 0.5636, 0.5476, 0.535]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.742, 0.685, 0.6393, 0.5983, 0.5682, 0.5615, 0.552, 0.5434, 0.529, 0.5168]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.723, 0.7345, 0.737, 0.7395, 0.7502, 0.7593, 0.7676, 0.7599, 0.7472, 0.738]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.721, 0.7345, 0.7363, 0.7395, 0.7502, 0.7598, 0.7679, 0.7601, 0.7471, 0.7368]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.725, 0.7375, 0.734, 0.736, 0.7436, 0.752, 0.76, 0.7507, 0.7381, 0.7289]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.79, 0.769, 0.7533, 0.737, 0.732, 0.7372, 0.7423, 0.7277, 0.7118, 0.6977]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.766, 0.784, 0.7887, 0.7863, 0.7862, 0.7868, 0.7876, 0.7704, 0.7541, 0.7398]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.746, 0.7635, 0.7607, 0.7653, 0.7792, 0.7833, 0.7846, 0.7724, 0.7567, 0.7422]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.76, 0.777, 0.786, 0.7895, 0.791, 0.7927, 0.7941, 0.78, 0.7623, 0.748]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.762, 0.784, 0.795, 0.7998, 0.801, 0.801, 0.8024, 0.789, 0.7728, 0.7578]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.802, 0.79, 0.7833, 0.7645, 0.7552, 0.7642, 0.771, 0.7607, 0.7459, 0.7357]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.803, 0.7875, 0.7823, 0.766, 0.758, 0.7652, 0.7726, 0.7627, 0.7481, 0.738]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.824, 0.806, 0.7853, 0.7658, 0.757, 0.7657, 0.7706, 0.7612, 0.7464, 0.7362]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.821, 0.801, 0.787, 0.766, 0.7568, 0.7648, 0.7704, 0.7602, 0.7458, 0.7352]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.801, 0.7985, 0.7953, 0.772, 0.757, 0.7553, 0.7589, 0.7457, 0.7281, 0.7174]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.799, 0.7955, 0.795, 0.761, 0.7364, 0.7327, 0.7289, 0.7082, 0.688, 0.6712]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.811, 0.8185, 0.8113, 0.7685, 0.7472, 0.7537, 0.76, 0.7484, 0.7334, 0.7217]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.805, 0.804, 0.811, 0.7903, 0.7702, 0.7732, 0.7741, 0.7632, 0.746, 0.7277]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.809, 0.806, 0.7883, 0.7685, 0.7576, 0.7655, 0.7739, 0.765, 0.753, 0.7437]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.805, 0.7975, 0.779, 0.7623, 0.755, 0.7642, 0.7706, 0.7605, 0.7458, 0.7344]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.816, 0.8015, 0.7873, 0.7663, 0.7574, 0.7667, 0.7721, 0.7622, 0.7473, 0.7371]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.821, 0.804, 0.7847, 0.7655, 0.7568, 0.7662, 0.7714, 0.7617, 0.747, 0.7366]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [13:31<00:00,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----8.09----\n",
      "Precisions: [0.814, 0.8245, 0.8243, 0.7928, 0.773, 0.78, 0.7797, 0.7592, 0.7391, 0.7217]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.07----\n",
      "Precisions: [0.741, 0.7885, 0.8047, 0.7965, 0.7932, 0.7918, 0.7906, 0.7689, 0.7484, 0.7313]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.826, 0.8055, 0.7947, 0.7853, 0.7902, 0.7942, 0.7959, 0.7829, 0.7667, 0.7525]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.693, 0.7505, 0.7573, 0.7595, 0.7532, 0.7555, 0.7599, 0.7502, 0.7351, 0.7221]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.808, 0.79, 0.792, 0.7745, 0.7672, 0.7772, 0.782, 0.7721, 0.7553, 0.7381]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.81, 0.8025, 0.8047, 0.7853, 0.7642, 0.7645, 0.769, 0.7619, 0.7478, 0.7337]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.824, 0.8215, 0.8117, 0.7953, 0.7824, 0.7868, 0.7894, 0.7756, 0.7561, 0.7434]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.819, 0.8145, 0.807, 0.7865, 0.7682, 0.7718, 0.7741, 0.7659, 0.7533, 0.7422]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.79, 0.7865, 0.7713, 0.7535, 0.741, 0.7282, 0.7143, 0.6991, 0.6834, 0.6637]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.748, 0.7405, 0.745, 0.723, 0.6996, 0.697, 0.6909, 0.6809, 0.6683, 0.6522]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.818, 0.823, 0.8217, 0.789, 0.7636, 0.758, 0.7489, 0.7346, 0.7153, 0.6969]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.06----\n",
      "Precisions: [0.731, 0.6865, 0.7077, 0.6833, 0.6392, 0.6273, 0.6321, 0.6326, 0.6288, 0.6153]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.7894\n",
      " 2. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.7886\n",
      " 3. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.7865\n",
      " 4. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.7860\n",
      " 5. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.7808\n",
      " 6. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.7802\n",
      " 7. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.7795\n",
      " 8. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.7789\n",
      " 9. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.7781\n",
      "10. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.7777\n",
      "11. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.7765\n",
      "12. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.7756\n",
      "13. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.7755\n",
      "14. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.7750\n",
      "15. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.7744\n",
      "16. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.7731\n",
      "17. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.7718\n",
      "18. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.7715\n",
      "19. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.7714\n",
      "20. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.7708\n",
      "21. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.7683\n",
      "22. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.7674\n",
      "23. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.7674\n",
      "24. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.7672\n",
      "25. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.7669\n",
      "26. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.7654\n",
      "27. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.7629\n",
      "28. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.7580\n",
      "29. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.7552\n",
      "30. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.7456\n",
      "31. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.7453\n",
      "32. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.7436\n",
      "33. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.7416\n",
      "34. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.7414\n",
      "35. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.7406\n",
      "36. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.7398\n",
      "37. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.7331\n",
      "38. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.7274\n",
      "39. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.7131\n",
      "40. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.7093\n",
      "41. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.7045\n",
      "42. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.7024\n",
      "43. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.6881\n",
      "44. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.6584\n",
      "45. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.6280\n",
      "46. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.6080\n",
      "47. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.5936\n",
      "48. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.5698\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "step = 10\n",
    "ground_truth_path = 'C:/Projects/benchmarks/d3l/d3l_ground_truth_sample.csv'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/d3l/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)\n",
    "\n",
    "#Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.7994\n",
    "#Supernormalized ->   1. Model: model                | Avg Precision: 0.7777\n",
    "\n",
    "# Prenormalized_all:  1. Model: gradient_boosting_custom | Avg Precision: 0.7878\n",
    "                    # 2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.7300\n",
    "\n",
    "# Prenormalized_base:  1. Model: gradient_boosting_custom | Avg Precision: 0.7886\n",
    "                    #  2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.7290\n",
    "\n",
    "# Res                    1. Model: gradient_boosting_custom | Avg Precision: 0.7798\n",
    "                    #   2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.7342\n",
    "\n",
    "# postnormalized_base:  1. Model: gradient_boosting_custom | Avg Precision: 0.7502\n",
    "                #       2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.7358\n",
    "\n",
    "\n",
    "# postnormalized_all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 25.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [1.0, 0.98, 0.96, 0.95, 0.94, 0.93, 0.9286, 0.9275, 0.9178, 0.908]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 35.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.01----\n",
      "Precisions: [1.0, 0.98, 0.9667, 0.945, 0.928, 0.9267, 0.9286, 0.9275, 0.9244, 0.926]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.96, 0.96, 0.952, 0.9467, 0.94, 0.9325, 0.92, 0.916]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.96, 0.94, 0.935, 0.924, 0.9233, 0.92, 0.9125, 0.9067, 0.904]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.9267, 0.915, 0.912, 0.91, 0.9086, 0.8975, 0.8911, 0.89]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.94, 0.92, 0.895, 0.884, 0.8833, 0.8886, 0.885, 0.8733, 0.872]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.94, 0.9267, 0.915, 0.912, 0.91, 0.9086, 0.91, 0.8911, 0.88]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.91, 0.9, 0.885, 0.876, 0.8667, 0.8543, 0.845, 0.8422, 0.846]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.01----\n",
      "Precisions: [1.0, 0.94, 0.9267, 0.935, 0.94, 0.9367, 0.92, 0.9175, 0.8978, 0.898]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.9533, 0.945, 0.94, 0.9267, 0.9286, 0.925, 0.9156, 0.906]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.95, 0.9267, 0.925, 0.908, 0.9, 0.8943, 0.885, 0.8689, 0.858]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.96, 0.94, 0.95, 0.94, 0.9367, 0.9257, 0.915, 0.9022, 0.904]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.93, 0.9, 0.9, 0.9, 0.89, 0.88, 0.87, 0.8644, 0.848]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.9, 0.8733, 0.865, 0.86, 0.8533, 0.8486, 0.8375, 0.8267, 0.814]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.9333, 0.91, 0.9, 0.8867, 0.8743, 0.8675, 0.86, 0.848]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.94, 0.9, 0.88, 0.868, 0.8567, 0.8514, 0.8275, 0.8133, 0.798]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.98, 0.96, 0.96, 0.965, 0.956, 0.9467, 0.9429, 0.935, 0.9311, 0.932]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.98, 0.96, 0.96, 0.965, 0.956, 0.9467, 0.9429, 0.935, 0.9311, 0.932]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.98, 0.97, 0.96, 0.97, 0.968, 0.9567, 0.94, 0.935, 0.9311, 0.928]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9667, 0.975, 0.964, 0.9567, 0.9486, 0.9425, 0.9311, 0.922]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.96, 0.9467, 0.925, 0.92, 0.92, 0.9114, 0.915, 0.9044, 0.888]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.99, 0.9667, 0.94, 0.936, 0.9333, 0.9257, 0.9275, 0.9156, 0.898]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.94, 0.93, 0.924, 0.9267, 0.9229, 0.9225, 0.9089, 0.898]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9533, 0.935, 0.924, 0.9267, 0.9257, 0.92, 0.9067, 0.898]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9733, 0.95, 0.932, 0.9367, 0.9343, 0.9325, 0.9289, 0.928]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.99, 0.98, 0.98, 0.964, 0.9533, 0.9486, 0.945, 0.9422, 0.936]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.99, 0.9867, 0.98, 0.956, 0.95, 0.9457, 0.935, 0.9311, 0.932]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.99, 0.9867, 0.98, 0.976, 0.96, 0.9543, 0.9425, 0.9422, 0.934]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9333, 0.915, 0.904, 0.9033, 0.8914, 0.89, 0.8822, 0.884]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9333, 0.93, 0.924, 0.92, 0.9171, 0.91, 0.8978, 0.896]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9333, 0.93, 0.928, 0.92, 0.9086, 0.8925, 0.8911, 0.886]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.99, 0.9533, 0.935, 0.916, 0.9167, 0.9086, 0.9025, 0.9, 0.89]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9667, 0.965, 0.96, 0.9567, 0.9514, 0.9475, 0.9356, 0.928]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9733, 0.95, 0.936, 0.9367, 0.9343, 0.935, 0.9311, 0.928]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.99, 0.98, 0.98, 0.964, 0.9567, 0.9543, 0.945, 0.9333, 0.932]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.99, 0.9867, 0.975, 0.968, 0.96, 0.9514, 0.9375, 0.9311, 0.93]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9467, 0.935, 0.92, 0.9133, 0.9086, 0.9025, 0.8956, 0.89]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.96, 0.94, 0.925, 0.908, 0.9067, 0.8943, 0.8875, 0.8822, 0.884]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9467, 0.92, 0.904, 0.91, 0.9143, 0.9075, 0.9022, 0.898]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.94, 0.92, 0.912, 0.92, 0.92, 0.9075, 0.8933, 0.89]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.9533, 0.945, 0.94, 0.9367, 0.9343, 0.9325, 0.9289, 0.924]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.98, 0.96, 0.955, 0.948, 0.9433, 0.9314, 0.9175, 0.9133, 0.91]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.9533, 0.95, 0.932, 0.93, 0.9286, 0.9175, 0.9156, 0.914]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.97, 0.9533, 0.945, 0.94, 0.9367, 0.9286, 0.9225, 0.92, 0.914]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.93, 0.9067, 0.905, 0.896, 0.9, 0.9029, 0.895, 0.8889, 0.884]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.93, 0.8733, 0.865, 0.868, 0.86, 0.86, 0.8425, 0.8311, 0.83]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.96, 0.9333, 0.935, 0.916, 0.9, 0.8971, 0.8925, 0.8778, 0.874]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [1.0, 0.93, 0.8933, 0.895, 0.892, 0.8833, 0.8829, 0.885, 0.8778, 0.874]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9666\n",
      " 2. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.9639\n",
      " 3. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.9635\n",
      " 4. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.9630\n",
      " 5. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.9607\n",
      " 6. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.9591\n",
      " 7. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.9587\n",
      " 8. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.9539\n",
      " 9. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.9509\n",
      "10. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.9509\n",
      "11. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.9504\n",
      "12. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.9497\n",
      "13. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.9496\n",
      "14. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.9475\n",
      "15. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.9458\n",
      "16. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.9453\n",
      "17. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.9442\n",
      "18. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.9433\n",
      "19. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9430\n",
      "20. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.9411\n",
      "21. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.9410\n",
      "22. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.9374\n",
      "23. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.9369\n",
      "24. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.9343\n",
      "25. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.9325\n",
      "26. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.9312\n",
      "27. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.9312\n",
      "28. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.9308\n",
      "29. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9292\n",
      "30. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9290\n",
      "31. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.9283\n",
      "32. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.9273\n",
      "33. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.9269\n",
      "34. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.9221\n",
      "35. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.9193\n",
      "36. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.9188\n",
      "37. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.9186\n",
      "38. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.9183\n",
      "39. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.9116\n",
      "40. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.9108\n",
      "41. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.9050\n",
      "42. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.9041\n",
      "43. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.9013\n",
      "44. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.8982\n",
      "45. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.8825\n",
      "46. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.8760\n",
      "47. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.8735\n",
      "48. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.8678\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "step = 1\n",
    "ground_truth_path = 'C:/Projects/benchmarks/freyja/freyja_ground_truth.csv'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/freyja/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)\n",
    "\n",
    "# Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.9504\n",
    "# Supernormalized -> 1. Model: model                | Avg Precision: 0.8942\n",
    "\n",
    "# Prenormalized_all:  1. Model: gradient_boosting_custom | Avg Precision: 0.9411\n",
    "                    # 2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.9300\n",
    "\n",
    "# prenormalized_base:  1. Model: gradient_boosting_custom | Avg Precision: 0.9411\n",
    "                    #  2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.9300\n",
    "\n",
    "# Res                    1. Model: gradient_boosting_custom | Avg Precision: 0.9411\n",
    "                    #   2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.9300       \n",
    "\n",
    "\n",
    "# postnormalized_base:  1. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.9392\n",
    "                    #   2. Model: extra_trees_all_fs_deep | Avg Precision: 0.8882\n",
    "\n",
    "\n",
    "# postnormalized_all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.04----\n",
      "Precisions: [0.604, 0.62, 0.6013, 0.585, 0.5688, 0.566]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.612, 0.604, 0.5893, 0.577, 0.576, 0.574]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.576, 0.594, 0.58, 0.573, 0.5752, 0.584]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.564, 0.61, 0.584, 0.585, 0.5736, 0.57]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 28.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.584, 0.6, 0.5933, 0.579, 0.5712, 0.5713]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.608, 0.628, 0.6013, 0.583, 0.5776, 0.568]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.556, 0.608, 0.6013, 0.571, 0.564, 0.566]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.52, 0.544, 0.508, 0.503, 0.52, 0.5227]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.544, 0.568, 0.54, 0.539, 0.5392, 0.5453]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.616, 0.602, 0.5907, 0.569, 0.5624, 0.5767]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.584, 0.602, 0.5787, 0.568, 0.5688, 0.5733]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.62, 0.616, 0.592, 0.583, 0.5736, 0.582]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.564, 0.592, 0.584, 0.567, 0.5528, 0.548]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.636, 0.624, 0.584, 0.562, 0.5496, 0.5447]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.592, 0.584, 0.572, 0.566, 0.5568, 0.544]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.56, 0.574, 0.5707, 0.541, 0.532, 0.5253]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.532, 0.552, 0.56, 0.54, 0.5408, 0.5473]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.532, 0.554, 0.5613, 0.539, 0.5408, 0.5473]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.564, 0.548, 0.5453, 0.525, 0.5256, 0.5307]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.552, 0.566, 0.56, 0.534, 0.5392, 0.5507]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.552, 0.56, 0.5387, 0.541, 0.552, 0.56]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.56, 0.578, 0.5747, 0.576, 0.5696, 0.5673]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.56, 0.584, 0.56, 0.552, 0.5592, 0.5607]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.56, 0.58, 0.56, 0.562, 0.5736, 0.574]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.596, 0.612, 0.5893, 0.567, 0.5664, 0.5647]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.588, 0.582, 0.568, 0.548, 0.5528, 0.5553]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.548, 0.558, 0.5627, 0.539, 0.5408, 0.548]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.568, 0.576, 0.556, 0.539, 0.5456, 0.548]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.58, 0.614, 0.6147, 0.612, 0.62, 0.616]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.612, 0.632, 0.608, 0.597, 0.5872, 0.5867]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.588, 0.61, 0.6173, 0.606, 0.588, 0.594]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.584, 0.634, 0.6027, 0.585, 0.592, 0.61]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.604, 0.576, 0.5493, 0.536, 0.5328, 0.5287]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.568, 0.578, 0.5747, 0.558, 0.5632, 0.5653]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.596, 0.582, 0.5627, 0.542, 0.5456, 0.5493]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.576, 0.572, 0.5613, 0.539, 0.5376, 0.544]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.592, 0.606, 0.5867, 0.566, 0.5768, 0.5753]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.596, 0.644, 0.6107, 0.586, 0.5952, 0.5993]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.588, 0.626, 0.624, 0.609, 0.6072, 0.5993]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.576, 0.6, 0.5787, 0.579, 0.5776, 0.57]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.576, 0.598, 0.5813, 0.575, 0.5728, 0.57]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.572, 0.596, 0.5933, 0.584, 0.5832, 0.586]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.556, 0.58, 0.5867, 0.576, 0.576, 0.564]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.604, 0.6, 0.58, 0.57, 0.5792, 0.5753]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.616, 0.614, 0.592, 0.572, 0.5672, 0.564]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.596, 0.586, 0.5587, 0.534, 0.5408, 0.542]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.592, 0.614, 0.5893, 0.592, 0.5872, 0.5833]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.584, 0.594, 0.5813, 0.573, 0.5752, 0.568]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.6095\n",
      " 2. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.6089\n",
      " 3. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.6052\n",
      " 4. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.6038\n",
      " 5. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.6013\n",
      " 6. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.6006\n",
      " 7. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.5944\n",
      " 8. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.5943\n",
      " 9. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.5930\n",
      "10. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.5908\n",
      "11. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.5887\n",
      "12. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.5875\n",
      "13. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.5861\n",
      "14. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.5857\n",
      "15. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.5847\n",
      "16. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.5838\n",
      "17. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.5834\n",
      "18. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.5831\n",
      "19. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.5826\n",
      "20. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.5811\n",
      "21. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.5804\n",
      "22. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.5802\n",
      "23. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.5793\n",
      "24. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.5791\n",
      "25. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.5788\n",
      "26. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.5777\n",
      "27. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.5731\n",
      "28. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.5709\n",
      "29. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.5691\n",
      "30. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.5683\n",
      "31. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.5680\n",
      "32. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.5679\n",
      "33. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.5657\n",
      "34. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.5629\n",
      "35. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.5627\n",
      "36. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.5596\n",
      "37. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.5554\n",
      "38. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.5550\n",
      "39. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.5545\n",
      "40. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.5506\n",
      "41. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.5505\n",
      "42. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.5503\n",
      "43. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.5494\n",
      "44. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.5459\n",
      "45. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.5457\n",
      "46. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.5454\n",
      "47. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.5398\n",
      "48. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.5196\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "step = 5\n",
    "ground_truth_path = 'C:/Projects/benchmarks/omnimatch_city_government/omnimatch_city_government_ground_truth.csv'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/omnimatch_city_government/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)\n",
    "\n",
    "# Originial -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.5416\n",
    "# Supernormalized -> 1. Model: gradient_boosting_custom | Avg Precision: 0.5725\n",
    "\n",
    "# prenormalized_all:  1. Model: gradient_boosting_custom | Avg Precision: 0.5824\n",
    "                    # 4. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.5554\n",
    "\n",
    "# prenormalized_base:  2. Model: gradient_boosting_custom | Avg Precision: 0.5731\n",
    "                    #  4. gradient_boosting_all_fs_deep | Avg Precision: 0.5560\n",
    "\n",
    "# Res:                  2. Model: gradient_boosting_custom | Avg Precision: 0.5713\n",
    "                    #   4. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.5356\n",
    "\n",
    "# postnormalized_base:   1. Model: gradient_boosting_custom | Avg Precision: 0.5805\n",
    "                    #    2. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.5696\n",
    "\n",
    "\n",
    "# postnormalized_all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 23.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.576, 0.596, 0.588, 0.579, 0.5808, 0.578]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.544, 0.6, 0.6227, 0.618, 0.6136, 0.6167]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.54, 0.596, 0.6173, 0.606, 0.6056, 0.6027]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.556, 0.612, 0.644, 0.628, 0.608, 0.6073]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.548, 0.61, 0.604, 0.609, 0.6, 0.5987]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.544, 0.602, 0.5987, 0.597, 0.5904, 0.5833]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.536, 0.578, 0.576, 0.582, 0.572, 0.574]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.504, 0.572, 0.5627, 0.565, 0.5704, 0.5727]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.504, 0.58, 0.5933, 0.594, 0.5896, 0.5853]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.56, 0.62, 0.6133, 0.619, 0.6072, 0.5947]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.496, 0.568, 0.5627, 0.57, 0.5704, 0.5667]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.556, 0.612, 0.6013, 0.593, 0.576, 0.5653]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.524, 0.564, 0.5707, 0.569, 0.5496, 0.536]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.548, 0.552, 0.544, 0.554, 0.5496, 0.5393]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.512, 0.534, 0.5013, 0.472, 0.4552, 0.4413]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.5, 0.548, 0.5467, 0.531, 0.5192, 0.504]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.508, 0.564, 0.5667, 0.57, 0.5704, 0.5627]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.508, 0.564, 0.5667, 0.57, 0.5704, 0.5627]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.496, 0.554, 0.5693, 0.574, 0.568, 0.5613]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.512, 0.564, 0.564, 0.566, 0.5656, 0.5567]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.532, 0.582, 0.5933, 0.582, 0.576, 0.5933]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.564, 0.576, 0.5893, 0.594, 0.5904, 0.5993]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.568, 0.582, 0.5773, 0.589, 0.5936, 0.604]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.552, 0.582, 0.5787, 0.591, 0.596, 0.6033]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.552, 0.596, 0.6253, 0.626, 0.6216, 0.6213]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.5, 0.56, 0.5707, 0.569, 0.564, 0.566]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 33.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.512, 0.562, 0.5707, 0.567, 0.5616, 0.5693]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.488, 0.562, 0.5813, 0.574, 0.564, 0.5653]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.584, 0.612, 0.612, 0.617, 0.6096, 0.61]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.584, 0.59, 0.5987, 0.597, 0.6, 0.6073]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.544, 0.576, 0.5707, 0.576, 0.5888, 0.6007]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.56, 0.576, 0.572, 0.585, 0.5848, 0.592]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.496, 0.568, 0.5587, 0.541, 0.5376, 0.5427]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.54, 0.594, 0.6213, 0.621, 0.6176, 0.6227]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.516, 0.566, 0.5733, 0.566, 0.5616, 0.566]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.504, 0.56, 0.5693, 0.566, 0.5608, 0.5713]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.544, 0.578, 0.5747, 0.592, 0.6056, 0.6107]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.528, 0.576, 0.5827, 0.606, 0.6016, 0.608]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.568, 0.59, 0.58, 0.583, 0.5856, 0.5947]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.544, 0.588, 0.5907, 0.588, 0.5808, 0.5927]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 28.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.03----\n",
      "Precisions: [0.524, 0.604, 0.6133, 0.606, 0.6064, 0.612]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.528, 0.59, 0.62, 0.614, 0.6048, 0.5987]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.564, 0.6, 0.588, 0.596, 0.6008, 0.602]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.564, 0.612, 0.6107, 0.609, 0.6112, 0.6087]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.552, 0.59, 0.5973, 0.592, 0.5896, 0.5833]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.512, 0.568, 0.56, 0.564, 0.5568, 0.5573]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 30.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.568, 0.612, 0.612, 0.607, 0.6048, 0.6133]\n",
      "------------------------------------------------------\n",
      "Model gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 31.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE time to load the distances and execute the model:\n",
      "----0.02----\n",
      "Precisions: [0.56, 0.58, 0.58, 0.583, 0.5808, 0.5847]\n",
      "------------------------------------------------------\n",
      "\n",
      "==================== MODEL RANKINGS ====================\n",
      " 1. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.6092\n",
      " 2. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.6074\n",
      " 3. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.6070\n",
      " 4. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.6028\n",
      " 5. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.6028\n",
      " 6. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.6026\n",
      " 7. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.6025\n",
      " 8. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.6024\n",
      " 9. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.5962\n",
      "10. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.5949\n",
      "11. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.5946\n",
      "12. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.5943\n",
      "13. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.5926\n",
      "14. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.5918\n",
      "15. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.5859\n",
      "16. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.5857\n",
      "17. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.5855\n",
      "18. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.5842\n",
      "19. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.5840\n",
      "20. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.5839\n",
      "21. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.5838\n",
      "22. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss0.8_msl10 | Avg Precision: 0.5837\n",
      "23. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.5835\n",
      "24. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.5830\n",
      "25. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.5807\n",
      "26. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.5783\n",
      "27. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.5781\n",
      "28. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md5_ss0.8_msl1 | Avg Precision: 0.5764\n",
      "29. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.5760\n",
      "30. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss0.8_msl1 | Avg Precision: 0.5744\n",
      "31. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl1 | Avg Precision: 0.5697\n",
      "32. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.5581\n",
      "33. Model: gradient_boosting_prenormalized_base_ne100_lr0.05_md5_ss1.0_msl10 | Avg Precision: 0.5578\n",
      "34. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.5571\n",
      "35. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.5570\n",
      "36. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss0.8_msl10 | Avg Precision: 0.5570\n",
      "37. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss1.0_msl10 | Avg Precision: 0.5558\n",
      "38. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md3_ss1.0_msl1 | Avg Precision: 0.5556\n",
      "39. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.5552\n",
      "40. Model: gradient_boosting_prenormalized_base_ne25_lr0.1_md3_ss0.8_msl10 | Avg Precision: 0.5549\n",
      "41. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl10 | Avg Precision: 0.5547\n",
      "42. Model: gradient_boosting_prenormalized_base_ne25_lr0.05_md3_ss1.0_msl1 | Avg Precision: 0.5538\n",
      "43. Model: gradient_boosting_prenormalized_base_ne50_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.5530\n",
      "44. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl1 | Avg Precision: 0.5522\n",
      "45. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss0.8_msl10 | Avg Precision: 0.5478\n",
      "46. Model: gradient_boosting_prenormalized_base_ne50_lr0.05_md3_ss0.8_msl1 | Avg Precision: 0.5407\n",
      "47. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl10 | Avg Precision: 0.5248\n",
      "48. Model: gradient_boosting_prenormalized_base_ne100_lr0.1_md5_ss1.0_msl1 | Avg Precision: 0.4860\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "step = 5\n",
    "ground_truth_path = 'C:/Projects/benchmarks/omnimatch_culture_recreation/omnimatch_culture_recreation_ground_truth.csv'\n",
    "distances_folder_path = 'C:/Projects/freyja_plus_more/distances/omnimatch_culture_recreation/distances_prenormalized_base/'\n",
    "\n",
    "evaluate_models(k, step, ground_truth_path, distances_folder_path)\n",
    "\n",
    "# Originail -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.5657\n",
    "# Supernormalized -> 1. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.6275\n",
    "\n",
    "# Prenormalized_all:  1. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.6259\n",
    "                    # 2. Model: gradient_boosting_custom | Avg Precision: 0.5956\n",
    "\n",
    "# prenormalized_base:  1. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.6230\n",
    "                    #  2. Model: gradient_boosting_custom | Avg Precision: 0.5918\n",
    "\n",
    "# res:                  1. Model: gradient_boosting_custom | Avg Precision: 0.5796\n",
    "                    #   3. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.5585     \n",
    "\n",
    "# postnormalized_base:  1. Model: gradient_boosting_all_fs_deep | Avg Precision: 0.6088\n",
    "                    #   2. Model: gradient_boosting_custom | Avg Precision: 0.6010\n",
    "\n",
    "\n",
    "# postnormalized_all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 models with individual benchmark scores:\n",
      "\n",
      "1. gradient_boosting_prenormalized_all_ne100_lr0.05_md3_ss1.0_msl10\n",
      "   Average score: 0.8148\n",
      "   Individual scores: ['0.9448', '0.9074', '0.7824', '0.9325', '0.5821', '0.6105', '0.9439']\n",
      "\n",
      "2. gradient_boosting_prenormalized_all_ne50_lr0.05_md5_ss1.0_msl1\n",
      "   Average score: 0.8139\n",
      "   Individual scores: ['0.9547', '0.9074', '0.7895', '0.9283', '0.6060', '0.5883', '0.9229']\n",
      "\n",
      "3. gradient_boosting_prenormalized_all_ne100_lr0.05_md3_ss1.0_msl1\n",
      "   Average score: 0.8139\n",
      "   Individual scores: ['0.9444', '0.9001', '0.7808', '0.9497', '0.5794', '0.6011', '0.9415']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prenormalized all\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path to your file\n",
    "file_path = \"final_tests_prenormalized_all.txt\"\n",
    "\n",
    "# Dictionary: model_name -> list of scores\n",
    "model_scores = defaultdict(list)\n",
    "\n",
    "# Regex to capture model name and Avg Precision\n",
    "pattern = re.compile(\n",
    "    r\"Model:\\s+(.*?)\\s+\\|\\s+Avg Precision:\\s+([0-9.]+)\"\n",
    ")\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        match = pattern.search(line)\n",
    "        if match:\n",
    "            model_name = match.group(1).strip()\n",
    "            score = float(match.group(2))\n",
    "            model_scores[model_name].append(score)\n",
    "\n",
    "# Compute average score per model\n",
    "model_avg = {\n",
    "    model: sum(scores) / len(scores)\n",
    "    for model, scores in model_scores.items()\n",
    "}\n",
    "\n",
    "# Sort models by average score (descending)\n",
    "sorted_models = sorted(\n",
    "    model_avg.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Print top 3 models with individual scores\n",
    "print(\"Top 3 models with individual benchmark scores:\\n\")\n",
    "\n",
    "for rank, (model, avg_score) in enumerate(sorted_models[:3], start=1):\n",
    "    scores = model_scores[model]\n",
    "    print(f\"{rank}. {model}\")\n",
    "    print(f\"   Average score: {avg_score:.4f}\")\n",
    "    print(f\"   Individual scores: {['{:.4f}'.format(s) for s in scores]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Santos_small ->   Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.9675\n",
    "# TUS_small ->      Original -> 2. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.8939\n",
    "# D3L ->            Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.7994\n",
    "# Freyja ->         Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.9504\n",
    "# OM_CG ->          Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.5416\n",
    "# OM_CR ->          Original -> 1. Model: gradient_boosting_no_syntactic_fs_deep | Avg Precision: 0.5657\n",
    "\n",
    "# 1. gradient_boosting_prenormalized_all_ne100_lr0.05_md3_ss1.0_msl10\n",
    "#    Average score: 0.8148\n",
    "#    Individual scores: ['0.9448', '0.9074', '0.7824', '0.9325', '0.5821', '0.6105', '0.9439']\n",
    "\n",
    "# 2. gradient_boosting_prenormalized_all_ne50_lr0.05_md5_ss1.0_msl1\n",
    "#    Average score: 0.8139\n",
    "#    Individual scores: ['0.9547', '0.9074', '0.7895', '0.9283', '0.6060', '0.5883', '0.9229']\n",
    "\n",
    "# 3. gradient_boosting_prenormalized_all_ne100_lr0.05_md3_ss1.0_msl1\n",
    "#    Average score: 0.8139\n",
    "#    Individual scores: ['0.9444', '0.9001', '0.7808', '0.9497', '0.5794', '0.6011', '0.9415']\n",
    "\n",
    "# Top 3 models with individual benchmark scores:\n",
    "\n",
    "# 1. gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n",
    "#    Average score: 0.8145\n",
    "#    Individual scores: ['0.9448', '0.9075', '0.7802', '0.9430', '0.5847', '0.6026', '0.9388']\n",
    "\n",
    "# 2. gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n",
    "#    Average score: 0.8142\n",
    "#    Individual scores: ['0.9448', '0.9081', '0.7789', '0.9325', '0.5811', '0.6092', '0.9450']\n",
    "\n",
    "# 3. gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n",
    "#    Average score: 0.8134\n",
    "#    Individual scores: ['0.9537', '0.9072', '0.7894', '0.9283', '0.6089', '0.5835', '0.9229']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 models with individual benchmark scores:\n",
      "\n",
      "1. gradient_boosting_prenormalized_base_ne50_lr0.1_md3_ss1.0_msl10\n",
      "   Average score: 0.8145\n",
      "   Individual scores: ['0.9448', '0.9075', '0.7802', '0.9430', '0.5847', '0.6026', '0.9388']\n",
      "\n",
      "2. gradient_boosting_prenormalized_base_ne100_lr0.05_md3_ss1.0_msl10\n",
      "   Average score: 0.8142\n",
      "   Individual scores: ['0.9448', '0.9081', '0.7789', '0.9325', '0.5811', '0.6092', '0.9450']\n",
      "\n",
      "3. gradient_boosting_prenormalized_base_ne50_lr0.05_md5_ss1.0_msl1\n",
      "   Average score: 0.8134\n",
      "   Individual scores: ['0.9537', '0.9072', '0.7894', '0.9283', '0.6089', '0.5835', '0.9229']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prenormalized all\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path to your file\n",
    "file_path = \"final_tests_prenormalized_base.txt\"\n",
    "\n",
    "# Dictionary: model_name -> list of scores\n",
    "model_scores = defaultdict(list)\n",
    "\n",
    "# Regex to capture model name and Avg Precision\n",
    "pattern = re.compile(\n",
    "    r\"Model:\\s+(.*?)\\s+\\|\\s+Avg Precision:\\s+([0-9.]+)\"\n",
    ")\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        match = pattern.search(line)\n",
    "        if match:\n",
    "            model_name = match.group(1).strip()\n",
    "            score = float(match.group(2))\n",
    "            model_scores[model_name].append(score)\n",
    "\n",
    "# Compute average score per model\n",
    "model_avg = {\n",
    "    model: sum(scores) / len(scores)\n",
    "    for model, scores in model_scores.items()\n",
    "}\n",
    "\n",
    "# Sort models by average score (descending)\n",
    "sorted_models = sorted(\n",
    "    model_avg.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Print top 3 models with individual scores\n",
    "print(\"Top 3 models with individual benchmark scores:\\n\")\n",
    "\n",
    "for rank, (model, avg_score) in enumerate(sorted_models[:3], start=1):\n",
    "    scores = model_scores[model]\n",
    "    print(f\"{rank}. {model}\")\n",
    "    print(f\"   Average score: {avg_score:.4f}\")\n",
    "    print(f\"   Individual scores: {['{:.4f}'.format(s) for s in scores]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Column names match.\n",
      "\n",
      "🔍 Value differences:\n",
      "Key=('animal_tag_data_a.csv', 'serial_no') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('civic_building_locations_1.csv', 'address2') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_0.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_0.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_1.csv', 'BusinessStreetLine1') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_1.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_2.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_2.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_3.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_3.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_10.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_4.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_4.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_5.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_5.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_6.csv', 'BusinessCity') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_6.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_6.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_7.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_7.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_8.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_8.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_9.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_9.csv', 'BusinessZip') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_b.csv', 'BusinessStreetLine1') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_b.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_a.csv', 'BusinessCity') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('complaint_by_practice_a.csv', 'BusinessState') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('HMRC_Officials_meetings_with_tobacco_stakeholders_Apr_2018_to_June_2018.csv', 'Unnamed: 2') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('minister_meetings_1.csv', 'Mode of Transport') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n",
      "Key=('senior_officials_expenses_3.csv', 'Other (including hospitality given)') | Column='first_word' | Dataset1='nan' | Dataset2='nan'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_datasets(path_1, path_2):\n",
    "    # Load datasets\n",
    "    df1 = pd.read_csv(path_1)\n",
    "    df2 = pd.read_csv(path_2)\n",
    "\n",
    "    # 1. Check column equality\n",
    "    if set(df1.columns) != set(df2.columns):\n",
    "        print(\"❌ Column names do not match.\")\n",
    "        print(\"Only in dataset 1:\", set(df1.columns) - set(df2.columns))\n",
    "        print(\"Only in dataset 2:\", set(df2.columns) - set(df1.columns))\n",
    "        return\n",
    "    else:\n",
    "        print(\"✅ Column names match.\")\n",
    "\n",
    "    # Ensure same column order\n",
    "    df2 = df2[df1.columns]\n",
    "\n",
    "    # Composite key\n",
    "    key_cols = [\"dataset_name\", \"attribute_name\"]\n",
    "\n",
    "    # Set index for comparison\n",
    "    df1 = df1.set_index(key_cols)\n",
    "    df2 = df2.set_index(key_cols)\n",
    "\n",
    "    # 2. Check for missing rows\n",
    "    only_in_df1 = df1.index.difference(df2.index)\n",
    "    only_in_df2 = df2.index.difference(df1.index)\n",
    "\n",
    "    if len(only_in_df1) > 0:\n",
    "        print(\"\\n⚠️ Rows only in dataset 1:\")\n",
    "        print(only_in_df1.tolist())\n",
    "\n",
    "    if len(only_in_df2) > 0:\n",
    "        print(\"\\n⚠️ Rows only in dataset 2:\")\n",
    "        print(only_in_df2.tolist())\n",
    "\n",
    "    # 3. Compare values for common rows\n",
    "    common_index = df1.index.intersection(df2.index)\n",
    "\n",
    "    print(\"\\n🔍 Value differences:\")\n",
    "    differences_found = False\n",
    "\n",
    "    for col in df1.columns:\n",
    "        diff_mask = df1.loc[common_index, col] != df2.loc[common_index, col]\n",
    "\n",
    "        if diff_mask.any():\n",
    "            differences_found = True\n",
    "            for idx in common_index[diff_mask]:\n",
    "                print(\n",
    "                    f\"Key={idx} | Column='{col}' | \"\n",
    "                    f\"Dataset1='{df1.loc[idx, col]}' | \"\n",
    "                    f\"Dataset2='{df2.loc[idx, col]}'\"\n",
    "                )\n",
    "\n",
    "    if not differences_found:\n",
    "        print(\"✅ No value differences found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    compare_datasets(\"C:/Projects/freyja_plus_more/profiles/profiles_santos_small.csv\", \n",
    "                     \"C:/Projects/FREYJA2/profiles/santos_small.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profiles\\omnimatch_culture_recreation_normalized.csv\n",
      "profiles\\omnimatch_culture_recreation_normalized.pkl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('profiles/omnimatch_culture_recreation.csv')\n",
    "path_with_suffix = path.with_stem(path.stem + \"_normalized\")\n",
    "output_profiles_path_preprocessed = path_with_suffix.with_suffix(\".pkl\")\n",
    "\n",
    "print(path_with_suffix)\n",
    "print(output_profiles_path_preprocessed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPphl2VZmBeT9V/QvoypH3j",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "freyja_plus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
